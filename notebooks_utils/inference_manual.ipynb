{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Scenario folder not found: data/RESULTS/6ac-1000-superdiverse/Scenario_00988",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 165\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Verify folder exists\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(SCENARIO_FOLDER):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScenario folder not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSCENARIO_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[1;32m    168\u001b[0m run_user_agent(SCENARIO_FOLDER)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Scenario folder not found: data/RESULTS/6ac-1000-superdiverse/Scenario_00988"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.utils import *\n",
    "from scripts.visualizations import *\n",
    "from src.config import *\n",
    "from datetime import datetime, timedelta\n",
    "from src.environment import AircraftDisruptionEnv\n",
    "from scripts.visualizations import StatePlotter\n",
    "from src.config import TIMESTEP_HOURS, DEBUG_MODE_PRINT_STATE\n",
    "import time\n",
    "\n",
    "env_type = \"proactive\"\n",
    "\n",
    "# Function to handle user input for action\n",
    "def get_user_action(valid_actions, env):\n",
    "    print(\"\\nAvailable Actions:\")\n",
    "    # for action_index in valid_actions:\n",
    "    #     flight, aircraft = env.map_index_to_action(action_index)\n",
    "    #     print(f\"Index {action_index}: Flight {flight}, Aircraft {aircraft}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"Enter the flight index from the available flights: \").strip()\n",
    "            flight_index = int(user_input)\n",
    "\n",
    "            user_input = input(\"Enter the aircraft index from the available aircrafts: \").strip()\n",
    "            aircraft_index = int(user_input)\n",
    "\n",
    "            action_index = env.map_action_to_index(flight_index, aircraft_index)\n",
    "\n",
    "            if action_index in valid_actions:\n",
    "                return action_index\n",
    "            else:\n",
    "                print(\"Invalid action index. Please select from the valid actions.\")\n",
    "                print(f\"available actions:\")\n",
    "                for action_index in valid_actions:\n",
    "                    flight, aircraft = env.map_index_to_action(action_index)\n",
    "                    print(f\"Index {action_index}: Flight {flight}, Aircraft {aircraft}\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number corresponding to the action index.\")\n",
    "\n",
    "# Run the agent with user input\n",
    "def run_user_agent(scenario_folder):\n",
    "    # Set a random seed based on the current second in time\n",
    "    current_seed = int(time.time() * 1e9) % (2**32 - 1)\n",
    "    print(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "\n",
    "    # Load the scenario data\n",
    "    data_dict = load_scenario_data(scenario_folder)\n",
    "\n",
    "    # Extract necessary data for the environment\n",
    "    aircraft_dict = data_dict['aircraft']\n",
    "    flights_dict = data_dict['flights']\n",
    "    rotations_dict = data_dict['rotations']\n",
    "    alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "    config_dict = data_dict['config']\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = AircraftDisruptionEnv(\n",
    "        aircraft_dict, flights_dict, rotations_dict, alt_aircraft_dict, config_dict, env_type=env_type\n",
    "    )\n",
    "\n",
    "    # Reset the environment\n",
    "    obs, info = env.reset()\n",
    "    if DEBUG_MODE_VISUALIZATION:\n",
    "        print(\"Observation keys:\", obs.keys())\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_num = 0\n",
    "\n",
    "    # Create StatePlotter object for visualizing the environment state\n",
    "    state_plotter = StatePlotter(\n",
    "        aircraft_dict=env.aircraft_dict,\n",
    "        flights_dict=env.flights_dict,\n",
    "        rotations_dict=env.rotations_dict,\n",
    "        alt_aircraft_dict=env.alt_aircraft_dict,\n",
    "        start_datetime=env.start_datetime,\n",
    "        end_datetime=env.end_datetime,\n",
    "        uncertain_breakdowns=env.uncertain_breakdowns,\n",
    "    )\n",
    "\n",
    "    # Print initial state\n",
    "    print(\"Initial State:\")\n",
    "    print_state_nicely(env.state)\n",
    "\n",
    "    while not done:\n",
    "        # Visualize the environment at each step\n",
    "        print(f\"\\nStep {step_num}:\")\n",
    "\n",
    "        # Extract necessary information for plotting\n",
    "        swapped_flights = env.swapped_flights\n",
    "        environment_delayed_flights = env.environment_delayed_flights\n",
    "        current_datetime = env.current_datetime\n",
    "\n",
    "        updated_flights_dict = env.flights_dict\n",
    "        updated_rotations_dict = env.rotations_dict\n",
    "        updated_alt_aircraft_dict = env.alt_aircraft_dict\n",
    "        cancelled_flights = env.penalized_cancelled_flights\n",
    "\n",
    "        # Update the StatePlotter's dictionaries\n",
    "        state_plotter.alt_aircraft_dict = updated_alt_aircraft_dict\n",
    "        state_plotter.flights_dict = updated_flights_dict\n",
    "        state_plotter.rotations_dict = updated_rotations_dict\n",
    "\n",
    "        # Plot the state\n",
    "        state_plotter.plot_state(\n",
    "            updated_flights_dict, swapped_flights, environment_delayed_flights, cancelled_flights, current_datetime\n",
    "        )\n",
    "\n",
    "        # Get the action mask\n",
    "        action_mask = obs['action_mask']\n",
    "        valid_actions = np.where(action_mask == 1)[0]\n",
    "\n",
    "        if len(valid_actions) == 0:\n",
    "            print(\"No valid actions available. Terminating...\")\n",
    "            break\n",
    "\n",
    "        # Get user input for the action\n",
    "        action_index = get_user_action(valid_actions, env)\n",
    "\n",
    "        # Map the action index to the actual action\n",
    "        action = env.map_index_to_action(action_index)\n",
    "        print(f\"Action chosen: Flight {action[0]}, Aircraft {action[1]}\")\n",
    "\n",
    "        # Step the environment\n",
    "        obs, reward, terminated, truncated, info = env.step(action_index)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Accumulate reward\n",
    "        total_reward += reward\n",
    "\n",
    "        # Print action and reward\n",
    "        print(f\"Action taken: Flight {action[0]}, Aircraft {action[1]}, Reward: {reward}\")\n",
    "\n",
    "        step_num += 1\n",
    "\n",
    "    # Final plot after the simulation ends\n",
    "    state_plotter.plot_state(\n",
    "        updated_flights_dict, swapped_flights, environment_delayed_flights, cancelled_flights,\n",
    "        current_datetime + timedelta(hours=TIMESTEP_HOURS)\n",
    "    )\n",
    "\n",
    "    if DEBUG_MODE_PRINT_STATE:\n",
    "        print(\"Final State:\")\n",
    "        print_state_nicely(env.state, env_type)\n",
    "\n",
    "    print(f\"Total Reward: {total_reward}\")\n",
    "\n",
    "# Set the scenario folder\n",
    "# SCENARIO_FOLDER = \"../data/Training/3ac-100/Scenario_57\"\n",
    "\n",
    "# SCENARIO_FOLDER = \"../data/Training/3ac-5-deterministic-na/Scenario_02\"\n",
    "# SCENARIO_FOLDER = \"../data/Training/3ac-5-deterministic-na/Scenario_01\"\n",
    "# SCENARIO_FOLDER = \"../data/Training/6ac-100-deterministic/Scenario_00003\"\n",
    "SCENARIO_FOLDER = \"data/RESULTS/6ac-1000-superdiverse/Scenario_00988\"\n",
    "\n",
    "# Verify folder exists\n",
    "if not os.path.exists(SCENARIO_FOLDER):\n",
    "    raise FileNotFoundError(f\"Scenario folder not found: {SCENARIO_FOLDER}\")\n",
    "\n",
    "# Run the agent\n",
    "run_user_agent(SCENARIO_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
