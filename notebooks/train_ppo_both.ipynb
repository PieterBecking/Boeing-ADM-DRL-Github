{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "CUDA available: False\n",
      "Number of GPUs available: 0\n",
      "cuDNN enabled: True\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Device info: {'device_type': 'MacBook M1'}\n",
      "Training folders: ['Scenario_01']\n",
      "Training on 50 days of data (50 episodes of 1 scenarios)\n",
      "Getting model version for 3ac-single-cleared\n",
      "Models will be saved to:\n",
      "   ../trained_models/ppo/myopic_3ac-single-cleared-50-1.zip\n",
      "   ../trained_models/ppo/proactive_3ac-single-cleared-50-1.zip\n",
      "Results directory created at: ../results/ppo/20241123-20-41\n",
      "Using mps device\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-11-23-20-41-02-354934\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 164  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 12   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "myopic: Episode 1/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047144104 |\n",
      "|    clip_fraction        | 0.48        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | -1.43e-06   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.21e+06    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 2.63e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 2/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 166        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17667042 |\n",
      "|    clip_fraction        | 0.565      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.96      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 1.34e+06   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0362    |\n",
      "|    value_loss           | 2.64e+06   |\n",
      "----------------------------------------\n",
      "myopic: Episode 3/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017895084 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 7.21e-06    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.05e+06    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 2.51e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 4/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020399086 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.21e+06    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 2.67e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 5/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 165        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01789569 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.54      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 1.23e+06   |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0384    |\n",
      "|    value_loss           | 2.8e+06    |\n",
      "----------------------------------------\n",
      "myopic: Episode 6/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018430464 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.07e+06    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 2.78e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 7/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 166        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01814663 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.21      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 1.5e+06    |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 2.68e+06   |\n",
      "----------------------------------------\n",
      "myopic: Episode 8/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 165        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01970892 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.01      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 1.19e+06   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 2.9e+06    |\n",
      "----------------------------------------\n",
      "myopic: Episode 9/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023203796 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.18e+06    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 2.98e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 10/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019894037 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.39e+06    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 2.91e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 11/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014590122 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.54e+06    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 3.04e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 12/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010606846 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.7e+06     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 3.19e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 13/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020294216 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.82e+06    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 3.18e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 14/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006821788 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.24e+06    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    value_loss           | 3.12e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 15/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008842215 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.945      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.29e+06    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 2.93e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 16/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003201352 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.16e+06    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 2.81e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 17/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038173469 |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.785       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.38e+06     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 2.64e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 18/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613596 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.19e+06    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    value_loss           | 2.49e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 19/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007461293 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.19e+06    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 2.5e+06     |\n",
      "-----------------------------------------\n",
      "myopic: Episode 20/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011701488 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.75       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 8.64e+05    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 2.31e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 21/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060375705 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.741       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.08e+06     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 2.28e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 22/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013320324 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.54e+06    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    value_loss           | 2.35e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 23/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005262575 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.13e+06    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 2.18e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 24/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053768037 |\n",
      "|    clip_fraction        | 0.0753       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.06e+06     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    value_loss           | 2.24e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 25/50 completed.\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 163       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.720718  |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.417    |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 1.05e+06  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | 0.0948    |\n",
      "|    value_loss           | 2.33e+06  |\n",
      "---------------------------------------\n",
      "myopic: Episode 26/50 completed.\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4078536 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.226    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 6.72e+05  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.0196   |\n",
      "|    value_loss           | 1.06e+06  |\n",
      "---------------------------------------\n",
      "myopic: Episode 27/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 161        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22648801 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.493     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 6.28e+05   |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00337   |\n",
      "|    value_loss           | 1.52e+06   |\n",
      "----------------------------------------\n",
      "myopic: Episode 28/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017611872 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 7.06e+05    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 1.23e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 29/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068452125 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.675       |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 5.5e+05      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.27e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 30/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102324 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.86e+05    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 1.29e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 31/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01099544 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 3.98e+05   |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    value_loss           | 1.27e+06   |\n",
      "----------------------------------------\n",
      "myopic: Episode 32/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026022068 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.703       |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 5.1e+05      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.33e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 33/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003857058 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 4.1e+05     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 1.27e+06    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 34/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045240633 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.679       |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 4.17e+05     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000934    |\n",
      "|    value_loss           | 1.17e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 35/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01234936 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.676     |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 6.14e+05   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | 0.00623    |\n",
      "|    value_loss           | 1.13e+06   |\n",
      "----------------------------------------\n",
      "myopic: Episode 36/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033902072 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.696       |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 3.38e+05     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.05e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 37/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 159          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027044863 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.658       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 3.88e+05     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 38/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007913109 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.63e+05    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 1e+06       |\n",
      "-----------------------------------------\n",
      "myopic: Episode 39/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 163          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040203747 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 3.51e+05     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n",
      "myopic: Episode 40/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003250334 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.41e+05    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 9.16e+05    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 41/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016260573 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 4.77e+05     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 8.44e+05     |\n",
      "------------------------------------------\n",
      "myopic: Episode 42/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015467304 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 5.32e+05     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 8.31e+05     |\n",
      "------------------------------------------\n",
      "myopic: Episode 43/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 163        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00668895 |\n",
      "|    clip_fraction        | 0.0383     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.448     |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 2.82e+05   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    value_loss           | 7.61e+05   |\n",
      "----------------------------------------\n",
      "myopic: Episode 44/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 163          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019271593 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 5.58e+05     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    value_loss           | 7.2e+05      |\n",
      "------------------------------------------\n",
      "myopic: Episode 45/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031021591 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 3.48e+05     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 6.71e+05     |\n",
      "------------------------------------------\n",
      "myopic: Episode 46/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026531152 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.87e+05     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 5.39e+05     |\n",
      "------------------------------------------\n",
      "myopic: Episode 47/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022196162 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.55e+05     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 5.7e+05      |\n",
      "------------------------------------------\n",
      "myopic: Episode 48/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013745811 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.342       |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 2.71e+05     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 5.14e+05     |\n",
      "------------------------------------------\n",
      "myopic: Episode 49/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001216419 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.77e+05    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.000694   |\n",
      "|    value_loss           | 4.58e+05    |\n",
      "-----------------------------------------\n",
      "myopic: Episode 50/50 completed.\n",
      "Using mps device\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-11-23-20-55-22-876406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pieterbecking/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path '../trained_models/ppo' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 166  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 12   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "proactive: Episode 1/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061826073 |\n",
      "|    clip_fraction        | 0.466       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | -4.53e-06   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.17e+06    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0613     |\n",
      "|    value_loss           | 2.59e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 2/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10789311 |\n",
      "|    clip_fraction        | 0.533      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.94      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 1.3e+06    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 2.48e+06   |\n",
      "----------------------------------------\n",
      "proactive: Episode 3/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021958489 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.23e+06    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0593     |\n",
      "|    value_loss           | 2.52e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 4/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019926552 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.29e+06    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 2.6e+06     |\n",
      "-----------------------------------------\n",
      "proactive: Episode 5/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016043143 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.02e+06    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    value_loss           | 2.5e+06     |\n",
      "-----------------------------------------\n",
      "proactive: Episode 6/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015355077 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.68e+06    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    value_loss           | 2.72e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 7/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017667431 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.02e+06    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    value_loss           | 2.68e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 8/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016829917 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.29e+06    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 2.82e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 9/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015094415 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.21e+06    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 2.73e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 10/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015585401 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.62e+06    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 2.91e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 11/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024044784 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.43e+06    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 2.79e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 12/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010423876 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.78e+06    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 2.79e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 13/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011645054 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.5e+06     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 2.72e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 14/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072353235 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.43e+06     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 2.72e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 15/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 163         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017944805 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.62e+06    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 2.68e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 16/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 164          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047302963 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.34e+06     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 2.54e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 17/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009121962 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.985      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.24e+06    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 2.28e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 18/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005713569 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.34e+06    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    value_loss           | 2.45e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 19/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073722387 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.884       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.19e+06     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 2.27e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 20/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012995241 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 9.36e+05    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    value_loss           | 2.28e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 21/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005251173 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 6.62e+05    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 1.97e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 22/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015123964 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.11e+06    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 1.99e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 23/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027660811 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.765       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.23e+06     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 2.11e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 24/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008925648 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 9.93e+05    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    value_loss           | 1.92e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 25/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 159        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01758921 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.628     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 6.21e+05   |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.00138    |\n",
      "|    value_loss           | 1.78e+06   |\n",
      "----------------------------------------\n",
      "proactive: Episode 26/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 161          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038090884 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 8.96e+05     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 1.67e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 27/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026607323 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 8.36e+05    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.0245      |\n",
      "|    value_loss           | 1.73e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 28/50 completed.\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 161       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1086237 |\n",
      "|    clip_fraction        | 0.601     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.615    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 1.06e+06  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | 0.17      |\n",
      "|    value_loss           | 2.04e+06  |\n",
      "---------------------------------------\n",
      "proactive: Episode 29/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 161        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45591164 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 5.76e+05   |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 1.63e+06   |\n",
      "----------------------------------------\n",
      "proactive: Episode 30/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003585824 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 7.08e+05    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    value_loss           | 1.25e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 31/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005323544 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 9.31e+05    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 1.27e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 32/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031543644 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.617       |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 6.08e+05     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 1.16e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 33/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026044664 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 4.06e+05     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 1.07e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 34/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01772449 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.682     |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 4.81e+05   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00998   |\n",
      "|    value_loss           | 1.1e+06    |\n",
      "----------------------------------------\n",
      "proactive: Episode 35/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009975 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 4.45e+05    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 1.08e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 36/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011086324 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.14e+05    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 1.11e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 37/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011043967 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.92e+05    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    value_loss           | 1.23e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 38/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327763 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.42e+05    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    value_loss           | 1.16e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 39/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 166        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01123963 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.755     |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 5.48e+05   |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 1.03e+06   |\n",
      "----------------------------------------\n",
      "proactive: Episode 40/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010158839 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 3.76e+05    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 1.06e+06    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 41/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 167          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061264616 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.717       |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 5.88e+05     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 1.09e+06     |\n",
      "------------------------------------------\n",
      "proactive: Episode 42/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 164        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00432201 |\n",
      "|    clip_fraction        | 0.0427     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.639     |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 4.78e+05   |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00287   |\n",
      "|    value_loss           | 9.44e+05   |\n",
      "----------------------------------------\n",
      "proactive: Episode 43/50 completed.\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 165        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888047 |\n",
      "|    clip_fraction        | 0.05       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.596     |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 3.77e+05   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00577   |\n",
      "|    value_loss           | 9.08e+05   |\n",
      "----------------------------------------\n",
      "proactive: Episode 44/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010396821 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 4.01e+05    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 9.33e+05    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 45/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007318234 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 3.52e+05    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 7.41e+05    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 46/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003753875 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 2.95e+05    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 7.22e+05    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 47/50 completed.\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 165          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044772043 |\n",
      "|    clip_fraction        | 0.0654       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 3.3e+05      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    value_loss           | 7.31e+05     |\n",
      "------------------------------------------\n",
      "proactive: Episode 48/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003904475 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 2.12e+05    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    value_loss           | 6.21e+05    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 49/50 completed.\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003217156 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 2.45e+05    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 5.82e+05    |\n",
      "-----------------------------------------\n",
      "proactive: Episode 50/50 completed.\n",
      "Myopic rewards saved to ../results/ppo/20241123-20-41/rewards_myopic.pkl\n",
      "Proactive rewards saved to ../results/ppo/20241123-20-41/rewards_proactive.pkl\n",
      "Total training time: 1717.457868 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import re\n",
    "import subprocess\n",
    "import torch as th\n",
    "import pickle\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scripts.utils import (\n",
    "    load_scenario_data,\n",
    "    verify_training_folders,\n",
    "    create_results_directory,\n",
    "    get_model_version,\n",
    "    format_days,\n",
    "    calculate_training_days,\n",
    "    initialize_device,\n",
    "    check_device_capabilities,\n",
    "    get_device_info,\n",
    ")\n",
    "from scripts.visualizations import *\n",
    "from src.config import *\n",
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from src.environment import AircraftDisruptionEnv\n",
    "\n",
    "# Constants and Training Settings\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.99\n",
    "BUFFER_SIZE = 50000 * 2\n",
    "BATCH_SIZE = 64 * 4\n",
    "TARGET_UPDATE_INTERVAL = 100\n",
    "MAX_TIMESTEPS = 50000\n",
    "NEURAL_NET_STRUCTURE = dict(net_arch=[256, 256 * 2, 256])\n",
    "LEARNING_STARTS = 0\n",
    "TRAIN_FREQ = 4\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_MIN = 0.025\n",
    "PERCENTAGE_MIN = 95\n",
    "N_EPISODES = 50\n",
    "TRAINING_FOLDERS_PATH = \"../data/Training/3ac-single-cleared/\"\n",
    "TESTING_FOLDERS_PATH = \"../data/Testing/3ac-single-cleared/\"\n",
    "\n",
    "# Initialize device\n",
    "device = initialize_device()\n",
    "check_device_capabilities()\n",
    "device_info = get_device_info(device)\n",
    "print(f\"Device info: {device_info}\")\n",
    "\n",
    "# Verify training folders and gather training data\n",
    "training_folders = verify_training_folders(TRAINING_FOLDERS_PATH)\n",
    "print(f\"Training folders: {training_folders}\")\n",
    "\n",
    "# Calculate training days and model naming\n",
    "num_days_trained_on = calculate_training_days(N_EPISODES, training_folders)\n",
    "print(f\"Training on {num_days_trained_on} days of data \"\n",
    "      f\"({N_EPISODES} episodes of {len(training_folders)} scenarios)\")\n",
    "\n",
    "formatted_days = format_days(num_days_trained_on)\n",
    "last_folder = os.path.basename(os.path.normpath(TRAINING_FOLDERS_PATH))\n",
    "model_name = last_folder\n",
    "model_version = get_model_version(model_name)\n",
    "MODEL_SAVE_PATH = f'../trained_models/ppo/'\n",
    "MODEL_SAVE_NAME = f'{model_name}-{formatted_days}-{model_version}.zip'\n",
    "print(f\"Models will be saved to:\")\n",
    "print(f\"   {MODEL_SAVE_PATH}myopic_{MODEL_SAVE_NAME}\")\n",
    "print(f\"   {MODEL_SAVE_PATH}proactive_{MODEL_SAVE_NAME}\")\n",
    "\n",
    "# Create results directory\n",
    "results_dir = create_results_directory(append_to_name='ppo')\n",
    "print(f\"Results directory created at: {results_dir}\")\n",
    "\n",
    "def get_action_masks(env):\n",
    "    return env.get_action_mask()\n",
    "\n",
    "def train_ppo_agent(env_type):\n",
    "    rewards = []\n",
    "    total_timesteps = 0\n",
    "    scenario_folders = [\n",
    "        os.path.join(TRAINING_FOLDERS_PATH, folder)\n",
    "        for folder in os.listdir(TRAINING_FOLDERS_PATH)\n",
    "        if os.path.isdir(os.path.join(TRAINING_FOLDERS_PATH, folder))\n",
    "    ]\n",
    "\n",
    "    class ScenarioEnvWrapper(gym.Env):\n",
    "        def __init__(self, scenario_folders, env_type):\n",
    "            super(ScenarioEnvWrapper, self).__init__()\n",
    "            self.scenario_folders = scenario_folders\n",
    "            self.env_type = env_type\n",
    "            self.current_scenario_idx = -1\n",
    "            self.load_next_scenario()\n",
    "\n",
    "            self.observation_space = self.env.observation_space\n",
    "            self.action_space = self.env.action_space\n",
    "\n",
    "        def load_next_scenario(self):\n",
    "            self.current_scenario_idx = (self.current_scenario_idx + 1) % len(self.scenario_folders)\n",
    "            scenario_folder = self.scenario_folders[self.current_scenario_idx]\n",
    "            data_dict = load_scenario_data(scenario_folder)\n",
    "            aircraft_dict = data_dict['aircraft']\n",
    "            flights_dict = data_dict['flights']\n",
    "            rotations_dict = data_dict['rotations']\n",
    "            alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "            config_dict = data_dict['config']\n",
    "\n",
    "            self.env = AircraftDisruptionEnv(\n",
    "                aircraft_dict,\n",
    "                flights_dict,\n",
    "                rotations_dict,\n",
    "                alt_aircraft_dict,\n",
    "                config_dict,\n",
    "                env_type=self.env_type\n",
    "            )\n",
    "\n",
    "        def reset(self, seed=None, options=None):\n",
    "            self.load_next_scenario()\n",
    "            result = self.env.reset(seed=seed, options=options)\n",
    "            return result\n",
    "\n",
    "        def step(self, action):\n",
    "            return self.env.step(action)\n",
    "\n",
    "        def render(self, mode='human'):\n",
    "            return self.env.render(mode=mode)\n",
    "\n",
    "        def close(self):\n",
    "            return self.env.close()\n",
    "\n",
    "        def get_action_mask(self):\n",
    "            return self.env.get_action_mask()\n",
    "\n",
    "    env = ScenarioEnvWrapper(scenario_folders, env_type)\n",
    "    env = ActionMasker(env, get_action_masks)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    model = MaskablePPO(\n",
    "        'MultiInputPolicy',\n",
    "        env,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        gamma=GAMMA,\n",
    "        verbose=1,\n",
    "        tensorboard_log=f\"./ppo_aircraft_tensorboard_{env_type}/\",\n",
    "        device=device,\n",
    "        policy_kwargs=NEURAL_NET_STRUCTURE\n",
    "    )\n",
    "\n",
    "    logger = configure()\n",
    "    model.set_logger(logger)\n",
    "\n",
    "    timesteps_per_episode = MAX_TIMESTEPS // N_EPISODES\n",
    "\n",
    "    for episode in range(N_EPISODES):\n",
    "        print(f\"{env_type}: Episode {episode + 1}/{N_EPISODES} started.\")\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        episode_rewards = []\n",
    "\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=False)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "        total_reward = sum(episode_rewards)\n",
    "        rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}: Reward: {total_reward}\")\n",
    "\n",
    "        model.learn(total_timesteps=timesteps_per_episode, reset_num_timesteps=False)\n",
    "        total_timesteps += timesteps_per_episode\n",
    "\n",
    "        print(f\"{env_type}: Episode {episode + 1}/{N_EPISODES} completed.\")\n",
    "\n",
    "    model.save(f\"{MODEL_SAVE_PATH}{env_type}_{MODEL_SAVE_NAME}\")\n",
    "    return rewards, total_timesteps\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "results_myopic = train_ppo_agent('myopic')\n",
    "results_proactive = train_ppo_agent('proactive')\n",
    "\n",
    "rewards_myopic, total_timesteps_myopic = results_myopic\n",
    "rewards_proactive, total_timesteps_proactive = results_proactive\n",
    "\n",
    "myopic_rewards_file = os.path.join(results_dir, \"rewards_myopic.pkl\")\n",
    "with open(myopic_rewards_file, \"wb\") as file:\n",
    "    pickle.dump(rewards_myopic, file)\n",
    "print(f\"Myopic rewards saved to {myopic_rewards_file}\")\n",
    "\n",
    "proactive_rewards_file = os.path.join(results_dir, \"rewards_proactive.pkl\")\n",
    "with open(proactive_rewards_file, \"wb\") as file:\n",
    "    pickle.dump(rewards_proactive, file)\n",
    "print(f\"Proactive rewards saved to {proactive_rewards_file}\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "runtime = (end_time - start_time).total_seconds()\n",
    "print(f\"Total training time: {runtime} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myopic rewards saved to ../results/ppo/20241123-20-41/rewards_myopic.pkl\n",
      "Proactive rewards saved to ../results/ppo/20241123-20-41/rewards_proactive.pkl\n",
      "Total training time: 1717.463233 seconds\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Save the myopic rewards\n",
    "myopic_rewards_file = os.path.join(results_dir, \"rewards_myopic.pkl\")\n",
    "with open(myopic_rewards_file, \"wb\") as file:\n",
    "    pickle.dump(rewards_myopic, file)\n",
    "print(f\"Myopic rewards saved to {myopic_rewards_file}\")\n",
    "\n",
    "# Save the proactive rewards\n",
    "proactive_rewards_file = os.path.join(results_dir, \"rewards_proactive.pkl\")\n",
    "with open(proactive_rewards_file, \"wb\") as file:\n",
    "    pickle.dump(rewards_proactive, file)\n",
    "print(f\"Proactive rewards saved to {proactive_rewards_file}\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "runtime = end_time - start_time\n",
    "runtime_in_seconds = runtime.total_seconds()\n",
    "print(f\"Total training time: {runtime_in_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All hyperparameters saved to ../results/ppo/20241123-20-41/hyperparameters.csv\n"
     ]
    }
   ],
   "source": [
    "from src.config import *\n",
    "\n",
    "# Create a dictionary of all hyperparameters and system information\n",
    "hyperparameters = {\n",
    "    \"Parameter\": [\n",
    "        \"MODEL_TYPE\",\n",
    "        \"LEARNING_RATE\", \"GAMMA\", \"BUFFER_SIZE\", \"BATCH_SIZE\",\n",
    "        \"TARGET_UPDATE_INTERVAL\", \"MAX_TIMESTEPS\", \"LEARNING_STARTS\",\n",
    "        \"TRAIN_FREQ\", \"N_EPISODES\", \"NEURAL_NET_STRUCTURE\",\n",
    "        \"TRAINING_FOLDERS_PATH\", \"TESTING_FOLDERS_PATH\", \"MODEL_SAVE_PATH\",\n",
    "        \"MODEL_SAVE_NAME\", \"runtime_in_seconds\", \"runtime_in_hh:mm:ss\",\n",
    "        \"total_timesteps_myopic\", \"total_timesteps_proactive\", \"device\",\n",
    "        \"device_info\", \"MAX_AIRCRAFT\", \"MAX_FLIGHTS_PER_AIRCRAFT\",\n",
    "        \"TIMESTEP_HOURS\", \"DUMMY_VALUE\", \"RESOLVED_CONFLICT_REWARD\",\n",
    "        \"DELAY_MINUTE_PENALTY\", \"MAX_DELAY_PENALTY\", \"NO_ACTION_PENALTY\",\n",
    "        \"CANCELLED_FLIGHT_PENALTY\", \"MIN_TURN_TIME\", \"CROSS_VAL_INTERVAL\",\n",
    "        \"PERCENTAGE_MIN\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        \"PPO\", LEARNING_RATE, GAMMA, BUFFER_SIZE, BATCH_SIZE,\n",
    "        TARGET_UPDATE_INTERVAL, MAX_TIMESTEPS, LEARNING_STARTS,\n",
    "        TRAIN_FREQ, N_EPISODES, str(NEURAL_NET_STRUCTURE),\n",
    "        TRAINING_FOLDERS_PATH, TESTING_FOLDERS_PATH, MODEL_SAVE_PATH,\n",
    "        MODEL_SAVE_NAME, runtime_in_seconds, str(runtime),\n",
    "        total_timesteps_myopic, total_timesteps_proactive, device,\n",
    "        str(device_info), MAX_AIRCRAFT, MAX_FLIGHTS_PER_AIRCRAFT,\n",
    "        TIMESTEP_HOURS, DUMMY_VALUE, RESOLVED_CONFLICT_REWARD,\n",
    "        DELAY_MINUTE_PENALTY, MAX_DELAY_PENALTY, NO_ACTION_PENALTY,\n",
    "        CANCELLED_FLIGHT_PENALTY, MIN_TURN_TIME, CROSS_VAL_INTERVAL,\n",
    "        PERCENTAGE_MIN\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "hyperparameters_df = pd.DataFrame(hyperparameters)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(results_dir, \"hyperparameters.csv\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "hyperparameters_df.to_csv(csv_file_path, index=False)\n",
    "print(f\"All hyperparameters saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process training rewards per episode for myopic\n",
    "print(rewards_myopic)\n",
    "episodes_myopic = [ep for ep, _ in rewards_myopic]\n",
    "avg_rewards_per_episode_myopic = [reward for _, reward in rewards_myopic]\n",
    "\n",
    "# Process training rewards per episode for proactive\n",
    "episodes_proactive = [ep for ep, _ in rewards_proactive]\n",
    "avg_rewards_per_episode_proactive = [reward for _, reward in rewards_proactive]\n",
    "\n",
    "# Extract test rewards for myopic\n",
    "# test_episodes_myopic = [ep for ep, _ in test_rewards_myopic]\n",
    "# test_avg_rewards_myopic = [reward for _, reward in test_rewards_myopic]\n",
    "\n",
    "# # Extract test rewards for proactive\n",
    "# test_episodes_proactive = [ep for ep, _ in test_rewards_proactive]\n",
    "# test_avg_rewards_proactive = [reward for _, reward in test_rewards_proactive]\n",
    "\n",
    "# Plot the average rewards over the episodes\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training rewards\n",
    "plt.plot(episodes_myopic, avg_rewards_per_episode_myopic, label='Myopic Training Reward', color='C0')\n",
    "plt.plot(episodes_proactive, avg_rewards_per_episode_proactive, label='Proactive Training Reward', color='C1')\n",
    "\n",
    "\n",
    "# plt.plot(test_episodes_myopic, test_avg_rewards_myopic, label='Myopic Test Reward', color='C0', linestyle='--')\n",
    "# plt.plot(test_episodes_proactive, test_avg_rewards_proactive, label='Proactive Test Reward', color='C1', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title('Average Reward per Episode')\n",
    "plt.savefig(os.path.join(results_dir, 'plots', 'average_reward_per_episode.png'))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
