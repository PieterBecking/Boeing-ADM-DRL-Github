{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'np': <module 'numpy' from '/Users/pieterbecking/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/numpy/__init__.py'>, 'MAX_AIRCRAFT': 6, 'MAX_FLIGHTS_PER_AIRCRAFT': 12, 'ROWS_STATE_SPACE': 7, 'COLUMNS_STATE_SPACE': 39, 'ACTION_SPACE_SIZE': 91, 'DEPARTURE_AFTER_END_RECOVERY': 1, 'TIMESTEP_HOURS': 1, 'DUMMY_VALUE': -999, 'RESOLVED_CONFLICT_REWARD': 10000, 'DELAY_MINUTE_PENALTY': 11.5, 'MAX_DELAY_PENALTY': 7500, 'NO_ACTION_PENALTY': 0, 'CANCELLED_FLIGHT_PENALTY': 1000, 'LAST_MINUTE_THRESHOLD': 120, 'LAST_MINUTE_FLIGHT_PENALTY': 455, 'AHEAD_BONUS_PER_MINUTE': 0.1, 'TIME_MINUTE_PENALTY': 1, 'TERMINATION_REWARD': 500, 'MIN_TURN_TIME': 0, 'MIN_BREAKDOWN_PROBABILITY': 0, 'DEBUG_MODE': False, 'DEBUG_MODE_TRAINING': False, 'DEBUG_MODE_REWARD': False, 'DEBUG_MODE_PRINT_STATE': False, 'DEBUG_MODE_CANCELLED_FLIGHT': False, 'DEBUG_MODE_VISUALIZATION': False, 'DEBUG_MODE_BREAKDOWN': False, 'DEBUG_MODE_ACTION': False, 'DEBUG_MODE_STOPPING_CRITERIA': False, 'DEBUG_MODE_SCHEDULING': False, 'DEBUG_MODE_REWARD_LAST_MINUTE_PENALTY': False, 'DEBUG_MODE_REWARD_RESOLVED_CONFLICTS': False}\n",
      "Step 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**** TRAINING_FOLDERS_PATH: ../data/Training/6ac-100-mixed-low/ ****\n",
      "\n",
      "\n",
      "\n",
      "--- DQN ---\n",
      "\n",
      "\n",
      "Training on 6ac-100-mixed-low\n",
      "Calculated EPSILON_DECAY_RATE: 0.003883031004330459\n",
      "EPSILON DECAY RATE:  0.003883031004330459\n",
      "Using device: mps\n",
      "CUDA available: False\n",
      "Number of GPUs available: 0\n",
      "cuDNN enabled: True\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Device info: {'device_type': 'MacBook M1'}\n",
      "Training on 5000 days of data (50 episodes of 100 scenarios)\n",
      "Results directory created at: ../results/dqn/20241209-10-50\n",
      "Running DQN training for seed 42...\n",
      "Models will be saved to: ../trained_models/dqn/myopic-1130.zip\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-12-09-10-50-16-111458\n",
      "(970/1000) myopic - episode 1 - epsilon 0.03 - reward this episode: 5149.97\n",
      "(1968/1000) myopic - episode 2 - epsilon 0.03 - reward this episode: 6513.36\n",
      "Models will be saved to: ../trained_models/dqn/proactive-1131.zip\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-12-09-10-50-19-196443\n",
      "(995/1000) proactive - episode 1 - epsilon 0.03 - reward this episode: 6120.62\n",
      "(2011/1000) proactive - episode 2 - epsilon 0.03 - reward this episode: 6464.53\n",
      "Models will be saved to: ../trained_models/dqn/reactive-1132.zip\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-12-09-10-50-22-015954\n",
      "(962/1000) reactive - episode 1 - epsilon 0.03 - reward this episode: 4428.81\n",
      "(1948/1000) reactive - episode 2 - epsilon 0.03 - reward this episode: 4158.14\n",
      "Running DQN training for seed 43...\n",
      "Models will be saved to: ../trained_models/dqn/myopic-1133.zip\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-12-09-10-50-24-794629\n",
      "(979/1000) myopic - episode 1 - epsilon 0.03 - reward this episode: 4631.53\n",
      "(1997/1000) myopic - episode 2 - epsilon 0.03 - reward this episode: 6665.01\n",
      "Models will be saved to: ../trained_models/dqn/proactive-1134.zip\n",
      "Device: mps\n",
      "Using MacBook M1\n",
      "Logging to /var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/SB3-2024-12-09-10-50-27-667532\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/3953532928.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m SEEDS:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning DQN training for seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     rewards_myopic, rewards_proactive, rewards_reactive, \\\n\u001b[0;32m---> 52\u001b[0m         test_rewards_myopic, test_rewards_proactive, test_rewards_reactive \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training_for_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Extract episode rewards and steps for myopic\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# episodes in rewards_myopic are keys like 0,1,2,... up to final trained episode\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Check \"avg_reward\" and \"total_timesteps\" exist for that episode\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     myopic_episode_rewards \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     58\u001b[0m         rewards_myopic[e][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(rewards_myopic\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rewards_myopic[e]\n\u001b[1;32m     60\u001b[0m     ]\n",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/3953532928.py:37\u001b[0m, in \u001b[0;36mrun_training_for_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     30\u001b[0m (rewards_myopic, test_rewards_myopic, total_timesteps_myopic, \n\u001b[1;32m     31\u001b[0m  epsilon_values_myopic, good_rewards_myopic, action_sequences_myopic, \n\u001b[1;32m     32\u001b[0m  model_path_and_name_myopic) \u001b[38;5;241m=\u001b[39m train_dqn_agent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyopic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train proactive agent\u001b[39;00m\n\u001b[1;32m     35\u001b[0m (rewards_proactive, test_rewards_proactive, total_timesteps_proactive, \n\u001b[1;32m     36\u001b[0m  epsilon_values_proactive, good_rewards_proactive, action_sequences_proactive, \n\u001b[0;32m---> 37\u001b[0m  model_path_and_name_proactive) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dqn_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproactive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train reactive agent  \u001b[39;00m\n\u001b[1;32m     40\u001b[0m (rewards_reactive, test_rewards_reactive, total_timesteps_reactive, \n\u001b[1;32m     41\u001b[0m  epsilon_values_reactive, good_rewards_reactive, action_sequences_reactive, \n\u001b[1;32m     42\u001b[0m  model_path_and_name_reactive) \u001b[38;5;241m=\u001b[39m train_dqn_agent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreactive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/1824284012.py:326\u001b[0m, in \u001b[0;36mtrain_dqn_agent\u001b[0;34m(env_type)\u001b[0m\n\u001b[1;32m    323\u001b[0m obs \u001b[38;5;241m=\u001b[39m {key: np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Preprocess observation and get Q-values\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    327\u001b[0m q_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mq_net(obs_tensor)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Apply the action mask (set invalid actions to -np.inf)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/policies.py:276\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_tensor, vectorized_env\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py:487\u001b[0m, in \u001b[0;36mobs_as_tensor\u001b[0;34m(obs, device)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th\u001b[38;5;241m.\u001b[39mas_tensor(_obs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py:487\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m\n\u001b[1;32m    112\u001b[0m stripped_scenario_folder \u001b[38;5;241m=\u001b[39m TRAINING_FOLDERS_PATH\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    113\u001b[0m save_results_big_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstripped_scenario_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_dqn_both_timesteps.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:737\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 737\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3005\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   3003\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 3005\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/3953532928.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m SEEDS:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning DQN training for seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     rewards_myopic, rewards_proactive, rewards_reactive, \\\n\u001b[0;32m---> 52\u001b[0m         test_rewards_myopic, test_rewards_proactive, test_rewards_reactive \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training_for_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Extract episode rewards and steps for myopic\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# episodes in rewards_myopic are keys like 0,1,2,... up to final trained episode\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Check \"avg_reward\" and \"total_timesteps\" exist for that episode\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     myopic_episode_rewards \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     58\u001b[0m         rewards_myopic[e][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(rewards_myopic\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rewards_myopic[e]\n\u001b[1;32m     60\u001b[0m     ]\n",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/3953532928.py:37\u001b[0m, in \u001b[0;36mrun_training_for_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     30\u001b[0m (rewards_myopic, test_rewards_myopic, total_timesteps_myopic, \n\u001b[1;32m     31\u001b[0m  epsilon_values_myopic, good_rewards_myopic, action_sequences_myopic, \n\u001b[1;32m     32\u001b[0m  model_path_and_name_myopic) \u001b[38;5;241m=\u001b[39m train_dqn_agent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyopic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train proactive agent\u001b[39;00m\n\u001b[1;32m     35\u001b[0m (rewards_proactive, test_rewards_proactive, total_timesteps_proactive, \n\u001b[1;32m     36\u001b[0m  epsilon_values_proactive, good_rewards_proactive, action_sequences_proactive, \n\u001b[0;32m---> 37\u001b[0m  model_path_and_name_proactive) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dqn_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproactive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train reactive agent  \u001b[39;00m\n\u001b[1;32m     40\u001b[0m (rewards_reactive, test_rewards_reactive, total_timesteps_reactive, \n\u001b[1;32m     41\u001b[0m  epsilon_values_reactive, good_rewards_reactive, action_sequences_reactive, \n\u001b[1;32m     42\u001b[0m  model_path_and_name_reactive) \u001b[38;5;241m=\u001b[39m train_dqn_agent(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreactive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_41285/1824284012.py:326\u001b[0m, in \u001b[0;36mtrain_dqn_agent\u001b[0;34m(env_type)\u001b[0m\n\u001b[1;32m    323\u001b[0m obs \u001b[38;5;241m=\u001b[39m {key: np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Preprocess observation and get Q-values\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    327\u001b[0m q_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mq_net(obs_tensor)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Apply the action mask (set invalid actions to -np.inf)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/policies.py:276\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_tensor, vectorized_env\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py:487\u001b[0m, in \u001b[0;36mobs_as_tensor\u001b[0;34m(obs, device)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th\u001b[38;5;241m.\u001b[39mas_tensor(_obs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Boeing-ADM-DRL-Github/.venv/lib/python3.10/site-packages/stable_baselines3/common/utils.py:487\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(obs, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized type of observation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import src.config as config\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "6ac-1-deterministic-na\n",
    "6ac-1-mixed-high\n",
    "6ac-1-mixed-low\n",
    "6ac-1-mixed-medium\n",
    "6ac-1-stochastic-high\n",
    "6ac-1-stochastic-low\n",
    "6ac-1-stochastic-medium\n",
    "6ac-10-deterministic-na\n",
    "6ac-10-mixed-high\n",
    "6ac-10-mixed-low\n",
    "6ac-10-mixed-medium\n",
    "6ac-10-stochastic-high\n",
    "6ac-10-stochastic-low\n",
    "6ac-10-stochastic-medium\n",
    "6ac-100-deterministic-na\n",
    "6ac-100-mixed-high\n",
    "6ac-100-mixed-low\n",
    "6ac-100-mixed-medium\n",
    "6ac-100-stochastic-high\n",
    "6ac-100-stochastic-low\n",
    "6ac-100-stochastic-medium\n",
    "6ac-1000-deterministic-na\n",
    "6ac-1000-mixed-high\n",
    "6ac-1000-mixed-low\n",
    "6ac-1000-mixed-medium\n",
    "6ac-1000-stochastic-high\n",
    "6ac-1000-stochastic-low\n",
    "6ac-1000-stochastic-medium\n",
    "\n",
    "\"\"\"\n",
    "all_folders = [\n",
    "    \"../data/Training/6ac-100-deterministic-na/\",\n",
    "    \"../data/Training/6ac-100-mixed-low/\",\n",
    "    \"../data/Training/6ac-100-mixed-medium/\",\n",
    "    \"../data/Training/6ac-100-mixed-high/\",\n",
    "    \"../data/Training/6ac-100-stochastic-low/\",\n",
    "    \"../data/Training/6ac-100-stochastic-medium/\",\n",
    "    \"../data/Training/6ac-100-stochastic-high/\",\n",
    "]\n",
    "all_folders_temp = [\n",
    "    \"../data/Training/6ac-100-mixed-low/\",\n",
    "    \"../data/Training/6ac-100-mixed-medium/\",\n",
    "    \"../data/Training/6ac-100-mixed-high/\",\n",
    "]\n",
    "\n",
    "def get_config_variables(config_module):\n",
    "    config_vars = {\n",
    "        key: value for key, value in vars(config_module).items()\n",
    "        if not key.startswith(\"__\") and not callable(value)  # Exclude magic methods and functions\n",
    "    }\n",
    "    return config_vars\n",
    "\n",
    "\n",
    "\n",
    "# In train_dqn_both_timesteps.ipynb:\n",
    "MAX_TOTAL_TIMESTEPS = 1000\n",
    "SEEDS = [42, 43, 44]\n",
    "brute_force_flag = False\n",
    "cross_val_flag = False\n",
    "early_stopping_flag = False\n",
    "CROSS_VAL_INTERVAL = 10000\n",
    "printing_intermediate_results = True\n",
    "\n",
    "save_folder = \"big-run-4\"\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "config_values = get_config_variables(config)\n",
    "# save all cofnig values form src/config.py to a csv in the save_results_big_run folder\n",
    "print(config_values)\n",
    "config_df = pd.DataFrame([config_values])  # Wrap config_values in a list to create a single row DataFrame\n",
    "\n",
    "config_df['MAX_TOTAL_TIMESTEPS'] = MAX_TOTAL_TIMESTEPS\n",
    "config_df['SEEDS'] = str([str(seed) for seed in SEEDS])\n",
    "config_df['brute_force_flag'] = brute_force_flag\n",
    "config_df['cross_val_flag'] = cross_val_flag\n",
    "config_df['early_stopping_flag'] = early_stopping_flag\n",
    "config_df['CROSS_VAL_INTERVAL'] = CROSS_VAL_INTERVAL\n",
    "config_df['printing_intermediate_results'] = printing_intermediate_results\n",
    "\n",
    "config_df.to_csv(f\"{save_folder}/config.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "step = 0\n",
    "for training_folder in all_folders_temp:\n",
    "    step += 1\n",
    "    print(f\"Step {step}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"**** TRAINING_FOLDERS_PATH: {training_folder} ****\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(\"--- DQN ---\")\n",
    "    print()\n",
    "    print()\n",
    "    TRAINING_FOLDERS_PATH = training_folder\n",
    "    \n",
    "    stripped_scenario_folder = TRAINING_FOLDERS_PATH.split(\"/\")[-2]\n",
    "    save_results_big_run = f\"{save_folder}/{stripped_scenario_folder}\"\n",
    "\n",
    "\n",
    "\n",
    "    %run train_dqn_both_timesteps.ipynb\n",
    "    print()\n",
    "    print()\n",
    "    print(\"--- PPO ---\")\n",
    "    print()\n",
    "    print() \n",
    "    # %run train_ppo_both.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
