{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 1:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0), ('B737#2', 4.0, 165.0, 377.0)}\n","\n","No current conflicts with probability 1.0 - taking no-op action (0, 0)\n","Selected action: index=0 (flight=0, aircraft=0)\n","Action result: reward=-60.0, terminated=False\n","\n","Step 2:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0), ('B737#2', 4.0, 165.0, 377.0)}\n","\n","No current conflicts with probability 1.0 - taking no-op action (0, 0)\n","Selected action: index=0 (flight=0, aircraft=0)\n","Action result: reward=-120.0, terminated=False\n","\n","Step 3:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0), ('B737#2', 4.0, 165.0, 377.0)}\n","\n","No current conflicts with probability 1.0 - taking no-op action (0, 0)\n","Selected action: index=0 (flight=0, aircraft=0)\n","Action result: reward=-180.0, terminated=False\n","\n","Step 4:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0)}\n","\n","No current conflicts with probability 1.0 - taking no-op action (0, 0)\n","Selected action: index=0 (flight=0, aircraft=0)\n","Action result: reward=-5240.0, terminated=False\n","\n","Step 5:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0)}\n","\n","Evaluating 85 valid actions:\n","  Action 0 (flight=0, aircraft=0): reward=-300.0\n","    -> New best action (reward=-300.0)\n","  Action 14 (flight=2, aircraft=0): reward=-5285.1\n","  Action 15 (flight=2, aircraft=1): reward=-2785.1\n","  Action 16 (flight=2, aircraft=2): reward=-2785.1\n","  Action 17 (flight=2, aircraft=3): reward=-2785.1\n","  Action 18 (flight=2, aircraft=4): reward=-2785.1\n","  Action 19 (flight=2, aircraft=5): reward=-1849.1\n","  Action 20 (flight=2, aircraft=6): reward=-1193.6\n","  Action 21 (flight=3, aircraft=0): reward=-5264.8\n","  Action 22 (flight=3, aircraft=1): reward=-2764.8\n","  Action 23 (flight=3, aircraft=2): reward=-2764.8\n","  Action 24 (flight=3, aircraft=3): reward=-2764.8\n","  Action 25 (flight=3, aircraft=4): reward=-2764.8\n","  Action 26 (flight=3, aircraft=5): reward=-2764.8\n","  Action 27 (flight=3, aircraft=6): reward=-264.8\n","    -> New best action (reward=-264.8)\n","  Action 35 (flight=5, aircraft=0): reward=-5284.7\n","  Action 36 (flight=5, aircraft=1): reward=-2784.7\n","  Action 37 (flight=5, aircraft=2): reward=-2800.0\n","  Action 38 (flight=5, aircraft=3): reward=-2784.7\n","  Action 39 (flight=5, aircraft=4): reward=-2784.7\n","  Action 40 (flight=5, aircraft=5): reward=-2101.7\n","  Action 41 (flight=5, aircraft=6): reward=-1147.2\n","  Action 42 (flight=6, aircraft=0): reward=-5262.2\n","  Action 43 (flight=6, aircraft=1): reward=-2762.2\n","  Action 44 (flight=6, aircraft=2): reward=-526.7\n","  Action 45 (flight=6, aircraft=3): reward=-2762.2\n","  Action 46 (flight=6, aircraft=4): reward=-2762.2\n","  Action 47 (flight=6, aircraft=5): reward=-2762.2\n","  Action 48 (flight=6, aircraft=6): reward=-262.2\n","    -> New best action (reward=-262.2)\n","  Action 56 (flight=8, aircraft=0): reward=-5278.8\n","  Action 57 (flight=8, aircraft=1): reward=-2778.8\n","  Action 58 (flight=8, aircraft=2): reward=-2778.8\n","  Action 59 (flight=8, aircraft=3): reward=-300.0\n","  Action 60 (flight=8, aircraft=4): reward=-2778.8\n","  Action 61 (flight=8, aircraft=5): reward=-2778.8\n","  Action 62 (flight=8, aircraft=6): reward=-462.8\n","  Action 63 (flight=9, aircraft=0): reward=-5257.8\n","  Action 64 (flight=9, aircraft=1): reward=-2695.8\n","  Action 65 (flight=9, aircraft=2): reward=-2757.8\n","  Action 66 (flight=9, aircraft=3): reward=-300.0\n","  Action 67 (flight=9, aircraft=4): reward=-2757.8\n","  Action 68 (flight=9, aircraft=5): reward=-2757.8\n","  Action 69 (flight=9, aircraft=6): reward=-257.8\n","    -> New best action (reward=-257.8)\n","  Action 77 (flight=11, aircraft=0): reward=-5295.6\n","  Action 78 (flight=11, aircraft=1): reward=-2795.6\n","  Action 79 (flight=11, aircraft=2): reward=-2795.6\n","  Action 80 (flight=11, aircraft=3): reward=-2795.6\n","  Action 81 (flight=11, aircraft=4): reward=-300.0\n","  Action 82 (flight=11, aircraft=5): reward=-537.1\n","  Action 83 (flight=11, aircraft=6): reward=-1997.6\n","  Action 84 (flight=12, aircraft=0): reward=-5271.4\n","  Action 85 (flight=12, aircraft=1): reward=-2771.4\n","  Action 86 (flight=12, aircraft=2): reward=-2771.4\n","  Action 87 (flight=12, aircraft=3): reward=-2771.4\n","  Action 88 (flight=12, aircraft=4): reward=-300.0\n","  Action 89 (flight=12, aircraft=5): reward=-2720.9\n","  Action 90 (flight=12, aircraft=6): reward=-271.4\n","  Action 91 (flight=13, aircraft=0): reward=-5250.0\n","  Action 92 (flight=13, aircraft=1): reward=-1791.0\n","  Action 93 (flight=13, aircraft=2): reward=-2239.5\n","  Action 94 (flight=13, aircraft=3): reward=-2124.5\n","  Action 95 (flight=13, aircraft=4): reward=-300.0\n","  Action 96 (flight=13, aircraft=5): reward=-1768.0\n","  Action 97 (flight=13, aircraft=6): reward=-250.0\n","    -> New best action (reward=-250.0)\n","  Action 105 (flight=15, aircraft=0): reward=-5289.8\n","  Action 106 (flight=15, aircraft=1): reward=-2789.8\n","  Action 107 (flight=15, aircraft=2): reward=-2789.8\n","  Action 108 (flight=15, aircraft=3): reward=-2060.8\n","  Action 109 (flight=15, aircraft=4): reward=-2789.8\n","  Action 110 (flight=15, aircraft=5): reward=-289.8\n","  Action 111 (flight=15, aircraft=6): reward=-300.0\n","  Action 112 (flight=16, aircraft=0): reward=-5275.5\n","  Action 113 (flight=16, aircraft=1): reward=-2775.5\n","  Action 114 (flight=16, aircraft=2): reward=-2775.5\n","  Action 115 (flight=16, aircraft=3): reward=-2775.5\n","  Action 116 (flight=16, aircraft=4): reward=-2081.0\n","  Action 117 (flight=16, aircraft=5): reward=-300.0\n","  Action 118 (flight=16, aircraft=6): reward=-275.5\n","  Action 119 (flight=17, aircraft=0): reward=-5257.1\n","  Action 120 (flight=17, aircraft=1): reward=-2614.6\n","  Action 121 (flight=17, aircraft=2): reward=-2757.1\n","  Action 122 (flight=17, aircraft=3): reward=-2757.1\n","  Action 123 (flight=17, aircraft=4): reward=-2757.1\n","  Action 124 (flight=17, aircraft=5): reward=-300.0\n","  Action 125 (flight=17, aircraft=6): reward=-257.1\n","\n","Chosen best action: index=97 (flight=13, aircraft=6) with reward=-250.0\n","Selected action: index=97 (flight=13, aircraft=6)\n","Action result: reward=-250.0, terminated=False\n","\n","Step 6:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0)}\n","\n","Evaluating 78 valid actions:\n","  Action 0 (flight=0, aircraft=0): reward=-360.0\n","    -> New best action (reward=-360.0)\n","  Action 14 (flight=2, aircraft=0): reward=-5351.1\n","  Action 15 (flight=2, aircraft=1): reward=-2851.1\n","  Action 16 (flight=2, aircraft=2): reward=-2851.1\n","  Action 17 (flight=2, aircraft=3): reward=-2851.1\n","  Action 18 (flight=2, aircraft=4): reward=-2851.1\n","  Action 19 (flight=2, aircraft=5): reward=-1915.1\n","  Action 20 (flight=2, aircraft=6): reward=-1259.6\n","  Action 21 (flight=3, aircraft=0): reward=-5330.8\n","  Action 22 (flight=3, aircraft=1): reward=-2830.8\n","  Action 23 (flight=3, aircraft=2): reward=-2830.8\n","  Action 24 (flight=3, aircraft=3): reward=-2830.8\n","  Action 25 (flight=3, aircraft=4): reward=-1710.8\n","  Action 26 (flight=3, aircraft=5): reward=-2830.8\n","  Action 27 (flight=3, aircraft=6): reward=-1676.3\n","  Action 35 (flight=5, aircraft=0): reward=-5350.7\n","  Action 36 (flight=5, aircraft=1): reward=-2850.7\n","  Action 37 (flight=5, aircraft=2): reward=-2860.0\n","  Action 38 (flight=5, aircraft=3): reward=-2850.7\n","  Action 39 (flight=5, aircraft=4): reward=-2850.7\n","  Action 40 (flight=5, aircraft=5): reward=-2167.7\n","  Action 41 (flight=5, aircraft=6): reward=-1213.2\n","  Action 42 (flight=6, aircraft=0): reward=-5328.2\n","  Action 43 (flight=6, aircraft=1): reward=-2828.2\n","  Action 44 (flight=6, aircraft=2): reward=-592.7\n","  Action 45 (flight=6, aircraft=3): reward=-2828.2\n","  Action 46 (flight=6, aircraft=4): reward=-1409.2\n","  Action 47 (flight=6, aircraft=5): reward=-2828.2\n","  Action 48 (flight=6, aircraft=6): reward=-2317.7\n","  Action 56 (flight=8, aircraft=0): reward=-5344.8\n","  Action 57 (flight=8, aircraft=1): reward=-2844.8\n","  Action 58 (flight=8, aircraft=2): reward=-2844.8\n","  Action 59 (flight=8, aircraft=3): reward=-360.0\n","  Action 60 (flight=8, aircraft=4): reward=-2391.8\n","  Action 61 (flight=8, aircraft=5): reward=-2844.8\n","  Action 62 (flight=8, aircraft=6): reward=-528.8\n","  Action 63 (flight=9, aircraft=0): reward=-5323.8\n","  Action 64 (flight=9, aircraft=1): reward=-2761.8\n","  Action 65 (flight=9, aircraft=2): reward=-2823.8\n","  Action 66 (flight=9, aircraft=3): reward=-360.0\n","  Action 67 (flight=9, aircraft=4): reward=-898.8\n","  Action 68 (flight=9, aircraft=5): reward=-2823.8\n","  Action 69 (flight=9, aircraft=6): reward=-2198.3\n","  Action 84 (flight=12, aircraft=0): reward=-5337.4\n","  Action 85 (flight=12, aircraft=1): reward=-2837.4\n","  Action 86 (flight=12, aircraft=2): reward=-2837.4\n","  Action 87 (flight=12, aircraft=3): reward=-2837.4\n","  Action 88 (flight=12, aircraft=4): reward=-360.0\n","  Action 89 (flight=12, aircraft=5): reward=-2786.9\n","  Action 90 (flight=12, aircraft=6): reward=-337.4\n","    -> New best action (reward=-337.4)\n","  Action 91 (flight=13, aircraft=0): reward=-5316.0\n","  Action 92 (flight=13, aircraft=1): reward=-1857.0\n","  Action 93 (flight=13, aircraft=2): reward=-2305.5\n","  Action 94 (flight=13, aircraft=3): reward=-2190.5\n","  Action 95 (flight=13, aircraft=4): reward=-316.0\n","    -> New best action (reward=-316.0)\n","  Action 96 (flight=13, aircraft=5): reward=-1834.0\n","  Action 97 (flight=13, aircraft=6): reward=-360.0\n","  Action 105 (flight=15, aircraft=0): reward=-5355.8\n","  Action 106 (flight=15, aircraft=1): reward=-2855.8\n","  Action 107 (flight=15, aircraft=2): reward=-2855.8\n","  Action 108 (flight=15, aircraft=3): reward=-2126.8\n","  Action 109 (flight=15, aircraft=4): reward=-2855.8\n","  Action 110 (flight=15, aircraft=5): reward=-355.8\n","  Action 111 (flight=15, aircraft=6): reward=-360.0\n","  Action 112 (flight=16, aircraft=0): reward=-5341.5\n","  Action 113 (flight=16, aircraft=1): reward=-2841.5\n","  Action 114 (flight=16, aircraft=2): reward=-2841.5\n","  Action 115 (flight=16, aircraft=3): reward=-2841.5\n","  Action 116 (flight=16, aircraft=4): reward=-1434.0\n","  Action 117 (flight=16, aircraft=5): reward=-360.0\n","  Action 118 (flight=16, aircraft=6): reward=-341.5\n","  Action 119 (flight=17, aircraft=0): reward=-5323.1\n","  Action 120 (flight=17, aircraft=1): reward=-2680.6\n","  Action 121 (flight=17, aircraft=2): reward=-2823.1\n","  Action 122 (flight=17, aircraft=3): reward=-2823.1\n","  Action 123 (flight=17, aircraft=4): reward=-817.6\n","  Action 124 (flight=17, aircraft=5): reward=-360.0\n","  Action 125 (flight=17, aircraft=6): reward=-1841.1\n","\n","Chosen best action: index=95 (flight=13, aircraft=4) with reward=-316.0\n","Selected action: index=95 (flight=13, aircraft=4)\n","Action result: reward=-316.0, terminated=False\n","\n","Step 7:\n","Current conflicts: {('B737#2', 6.0, 618.0, 913.0), ('B737#1', 3.0, 592.0, 857.0), ('B737#1', 2.0, 389.0, 582.0), ('B737#2', 5.0, 393.0, 593.0)}\n","\n","Evaluating 71 valid actions:\n","  Action 0 (flight=0, aircraft=0): reward=-10420.0\n","    -> New best action (reward=-10420.0)\n","  Action 14 (flight=2, aircraft=0): reward=-10417.1\n","    -> New best action (reward=-10417.1)\n","  Action 15 (flight=2, aircraft=1): reward=-7917.1\n","    -> New best action (reward=-7917.1)\n","  Action 16 (flight=2, aircraft=2): reward=-7917.1\n","  Action 17 (flight=2, aircraft=3): reward=-7917.1\n","  Action 18 (flight=2, aircraft=4): reward=-7917.1\n","  Action 19 (flight=2, aircraft=5): reward=-6981.1\n","    -> New best action (reward=-6981.1)\n","  Action 20 (flight=2, aircraft=6): reward=-6325.6\n","    -> New best action (reward=-6325.6)\n","  Action 21 (flight=3, aircraft=0): reward=-15396.8\n","  Action 22 (flight=3, aircraft=1): reward=-12896.8\n","  Action 23 (flight=3, aircraft=2): reward=-2896.8\n","    -> New best action (reward=-2896.8)\n","  Action 24 (flight=3, aircraft=3): reward=-12896.8\n","  Action 25 (flight=3, aircraft=4): reward=-12896.8\n","  Action 26 (flight=3, aircraft=5): reward=-12896.8\n","  Action 27 (flight=3, aircraft=6): reward=-10396.8\n","  Action 35 (flight=5, aircraft=0): reward=-10416.7\n","  Action 36 (flight=5, aircraft=1): reward=-7916.7\n","  Action 37 (flight=5, aircraft=2): reward=-7920.0\n","  Action 38 (flight=5, aircraft=3): reward=-7916.7\n","  Action 39 (flight=5, aircraft=4): reward=-7916.7\n","  Action 40 (flight=5, aircraft=5): reward=-7233.7\n","  Action 41 (flight=5, aircraft=6): reward=-6279.2\n","  Action 42 (flight=6, aircraft=0): reward=-15394.2\n","  Action 43 (flight=6, aircraft=1): reward=-12894.2\n","  Action 44 (flight=6, aircraft=2): reward=-10658.7\n","  Action 45 (flight=6, aircraft=3): reward=-12894.2\n","  Action 46 (flight=6, aircraft=4): reward=-12894.2\n","  Action 47 (flight=6, aircraft=5): reward=-12894.2\n","  Action 48 (flight=6, aircraft=6): reward=-10394.2\n","  Action 56 (flight=8, aircraft=0): reward=-15410.8\n","  Action 57 (flight=8, aircraft=1): reward=-12910.8\n","  Action 58 (flight=8, aircraft=2): reward=-12910.8\n","  Action 59 (flight=8, aircraft=3): reward=-10420.0\n","  Action 60 (flight=8, aircraft=4): reward=-12910.8\n","  Action 61 (flight=8, aircraft=5): reward=-12910.8\n","  Action 62 (flight=8, aircraft=6): reward=-10594.8\n","  Action 63 (flight=9, aircraft=0): reward=-15389.8\n","  Action 64 (flight=9, aircraft=1): reward=-12827.8\n","  Action 65 (flight=9, aircraft=2): reward=-12889.8\n","  Action 66 (flight=9, aircraft=3): reward=-10420.0\n","  Action 67 (flight=9, aircraft=4): reward=-12889.8\n","  Action 68 (flight=9, aircraft=5): reward=-12889.8\n","  Action 69 (flight=9, aircraft=6): reward=-10389.8\n","  Action 84 (flight=12, aircraft=0): reward=-15403.4\n","  Action 85 (flight=12, aircraft=1): reward=-12903.4\n","  Action 86 (flight=12, aircraft=2): reward=-12903.4\n","  Action 87 (flight=12, aircraft=3): reward=-12903.4\n","  Action 88 (flight=12, aircraft=4): reward=-10420.0\n","  Action 89 (flight=12, aircraft=5): reward=-12852.9\n","  Action 90 (flight=12, aircraft=6): reward=-10403.4\n","  Action 91 (flight=13, aircraft=0): reward=-15382.0\n","  Action 92 (flight=13, aircraft=1): reward=-11923.0\n","  Action 93 (flight=13, aircraft=2): reward=-12371.5\n","  Action 94 (flight=13, aircraft=3): reward=-12256.5\n","  Action 95 (flight=13, aircraft=4): reward=-10420.0\n","  Action 96 (flight=13, aircraft=5): reward=-11900.0\n","  Action 97 (flight=13, aircraft=6): reward=-10382.0\n","  Action 112 (flight=16, aircraft=0): reward=-15407.5\n","  Action 113 (flight=16, aircraft=1): reward=-12907.5\n","  Action 114 (flight=16, aircraft=2): reward=-12907.5\n","  Action 115 (flight=16, aircraft=3): reward=-12907.5\n","  Action 116 (flight=16, aircraft=4): reward=-12213.0\n","  Action 117 (flight=16, aircraft=5): reward=-10420.0\n","  Action 118 (flight=16, aircraft=6): reward=-10407.5\n","  Action 119 (flight=17, aircraft=0): reward=-15389.1\n","  Action 120 (flight=17, aircraft=1): reward=-12746.6\n","  Action 121 (flight=17, aircraft=2): reward=-12889.1\n","  Action 122 (flight=17, aircraft=3): reward=-12889.1\n","  Action 123 (flight=17, aircraft=4): reward=-12889.1\n","  Action 124 (flight=17, aircraft=5): reward=-10420.0\n","  Action 125 (flight=17, aircraft=6): reward=-10389.1\n","\n","Chosen best action: index=23 (flight=3, aircraft=2) with reward=-2896.8\n","Selected action: index=23 (flight=3, aircraft=2)\n","Action result: reward=-2896.8, terminated=True\n","\n","Action History Summary:\n","----------------------\n","Step | Flight | Aircraft |   Reward | Conflicts\n","---------------------------------------------\n","   1 |      0 |        0 |    -60.0 |         5\n","   2 |      0 |        0 |   -120.0 |         5\n","   3 |      0 |        0 |   -180.0 |         5\n","   4 |      0 |        0 |  -5240.0 |         4\n","   5 |     13 |        6 |   -250.0 |         4\n","   6 |     13 |        4 |   -316.0 |         4\n","   7 |      3 |        2 |  -2896.8 |         4\n","---------------------------------------------\n","Total Reward: -9062.8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b31a058882ac40eb85d016070b5648b9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(Button(description='⬅️', layout=Layout(width='40px'), style=ButtonStyle()), Button(description=…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f2f9ed7789f4a8ea56444c45fe50f19","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Optimization Results:\n","Objective value: 9062.80\n","\n","Solution statistics:\n","  Runtime: 0.25 seconds\n","  Status: Complete\n","\n","Solution summary:\n","  Cancelled flights: 0\n","  Total delay minutes: 337.0\n","  Number of reassignments: 0\n"]}],"source":["import os\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import ipywidgets as widgets\n","from IPython.display import display, clear_output, Image as IPImage\n","from datetime import datetime, timedelta\n","from scripts.utils import load_scenario_data\n","from src.environment import AircraftDisruptionOptimizer\n","from scripts.visualizations import StatePlotter\n","from scripts.utils import parse_time_with_day_offset\n","\n","# Set the same timestep as in the DQN environment\n","TIMESTEP_HOURS = 1  # Adjust if needed\n","\n","def run_exact_solution_and_plot(scenario_folder):\n","    data_dict = load_scenario_data(scenario_folder)\n","    aircraft_dict = data_dict['aircraft']\n","    flights_dict = data_dict['flights']\n","    rotations_dict = data_dict['rotations']\n","    alt_aircraft_dict = data_dict['alt_aircraft']\n","    config_dict = data_dict['config']\n","\n","    # Parse recovery period times\n","    recovery_period = config_dict['RecoveryPeriod']\n","    start_datetime = datetime.strptime(\n","        f\"{recovery_period['StartDate']} {recovery_period['StartTime']}\", '%d/%m/%y %H:%M'\n","    )\n","    end_datetime = datetime.strptime(\n","        f\"{recovery_period['EndDate']} {recovery_period['EndTime']}\", '%d/%m/%y %H:%M'\n","    )\n","\n","    optimizer = AircraftDisruptionOptimizer(\n","        aircraft_dict=aircraft_dict,\n","        flights_dict=flights_dict,\n","        rotations_dict=rotations_dict,\n","        alt_aircraft_dict=alt_aircraft_dict,\n","        config_dict=config_dict\n","    )\n","\n","    state_plotter = StatePlotter(\n","        aircraft_dict=aircraft_dict,\n","        flights_dict=flights_dict,\n","        rotations_dict=rotations_dict,\n","        alt_aircraft_dict=alt_aircraft_dict,\n","        start_datetime=start_datetime,\n","        end_datetime=end_datetime\n","    )\n","\n","    # Solve the problem once and store the solution\n","    solution = optimizer.solve()\n","\n","    # Extract solution details and action history\n","    cancellations = set(solution['cancellations'])\n","    delays = solution['delays']\n","    assignments = solution['assignments']  # flight_id -> new aircraft\n","    action_history = optimizer.action_history\n","\n","    # Create working copies of the dictionaries so we don't modify originals\n","    flights_dict_working = {k: v.copy() for k, v in flights_dict.items()}\n","    rotations_dict_working = {k: v.copy() for k, v in rotations_dict.items()}\n","\n","    # Lists to track applied actions at each timestep\n","    plots = []\n","    action_logs = []  # Store text descriptions of actions\n","\n","    def capture_plot_and_actions(title_suffix, current_datetime, actions_this_step):\n","        # Get current swapped flights\n","        swapped_flights = []\n","        for f_id, f_info in flights_dict_working.items():\n","            if 'NewAircraft' in f_info:\n","                swapped_flights.append((f_id, f_info['NewAircraft']))\n","        \n","        # Get current delayed and cancelled flights\n","        environment_delayed_flights = {f_id for f_id, f_info in flights_dict_working.items() \n","                                    if 'Delay' in f_info and f_info['Delay'] > 0}\n","        cancelled_flights = {f_id for f_id, f_info in flights_dict_working.items() \n","                           if 'Cancelled' in f_info and f_info['Cancelled']}\n","\n","        # Plot the current state\n","        fig = state_plotter.plot_state(\n","            flights_dict_working,\n","            swapped_flights=swapped_flights,\n","            environment_delayed_flights=environment_delayed_flights,\n","            cancelled_flights=cancelled_flights,\n","            current_datetime=current_datetime,\n","            title_appendix=f\"{title_suffix}\\n{actions_this_step}\",\n","            show_plot=False\n","        )\n","        buf = io.BytesIO()\n","        fig.savefig(buf, format='png')\n","        buf.seek(0)\n","        img = IPImage(data=buf.read(), format='png', embed=True)\n","        plots.append(img)\n","        action_logs.append(actions_this_step)\n","        plt.close(fig)\n","\n","    # Initial state plot\n","    capture_plot_and_actions(\"Initial State\", start_datetime, \"No actions yet\")\n","\n","    # Generate timesteps matching action history length\n","    time_steps = [start_datetime + timedelta(hours=i*TIMESTEP_HOURS) for i in range(len(action_history)+1)]\n","\n","    # Apply solution progressively based on action history\n","    for idx, t_step in enumerate(time_steps[1:], 1):  # Skip first timestep since it's initial state\n","        actions_this_step = []\n","        \n","        # Get action from history for this timestep\n","        action = action_history[idx-1]\n","        flight_id = action['flight']\n","        aircraft_id = action['aircraft']\n","        reward = action['reward']\n","        conflicts = action['conflicts']\n","        \n","        actions_this_step.append(f\"Step {idx}:\")\n","        actions_this_step.append(f\"Flight: {flight_id}, Aircraft: {aircraft_id}\")\n","        actions_this_step.append(f\"Reward: {reward:.1f}, Conflicts: {conflicts}\")\n","        \n","        if flight_id > 0:  # Non-zero flight ID means an actual action was taken\n","            # Apply the action\n","            if flight_id in flights_dict_working:\n","                if aircraft_id > 0:  # Reassignment\n","                    old_ac = rotations_dict[flight_id]['Aircraft']\n","                    new_ac = f'B737#{aircraft_id}'\n","                    flights_dict_working[flight_id]['NewAircraft'] = new_ac\n","                    rotations_dict_working[flight_id]['Aircraft'] = new_ac\n","                    actions_this_step.append(f\"Reassigned flight {flight_id} from {old_ac} to {new_ac}\")\n","\n","        action_text = \"\\n\".join(actions_this_step)\n","        capture_plot_and_actions(f\"Step {idx}\", t_step, action_text)\n","\n","    # Create widgets for navigation\n","    output = widgets.Output()\n","\n","    def update_display(index):\n","        with output:\n","            clear_output(wait=True)\n","            display(plots[index])\n","            print(\"\\nActions at this step:\")\n","            print(action_logs[index])\n","\n","    slider = widgets.IntSlider(\n","        value=0,\n","        min=0,\n","        max=len(plots)-1,\n","        step=1,\n","        description='Step:'\n","    )\n","\n","    def on_slider_change(change):\n","        if change['name'] == 'value':\n","            update_display(change['new'])\n","\n","    slider.observe(on_slider_change, names='value')\n","\n","    prev_button = widgets.Button(description='⬅️', layout=widgets.Layout(width='40px'))\n","    next_button = widgets.Button(description='➡️', layout=widgets.Layout(width='40px'))\n","\n","    def on_prev_button_clicked(b):\n","        slider.value = max(0, slider.value - 1)\n","\n","    def on_next_button_clicked(b):\n","        slider.value = min(len(plots)-1, slider.value + 1)\n","\n","    prev_button.on_click(on_prev_button_clicked)\n","    next_button.on_click(on_next_button_clicked)\n","\n","    navigation = widgets.HBox([prev_button, next_button, slider])\n","    update_display(0)\n","    display(navigation, output)\n","\n","    # Print final solution statistics\n","    print(\"\\nOptimization Results:\")\n","    print(f\"Objective value: {solution['objective_value']:.2f}\")\n","    print(f\"\\nSolution statistics:\")\n","    print(f\"  Runtime: {solution['statistics']['runtime']:.2f} seconds\")\n","    print(f\"  Status: {solution['statistics']['status']}\")\n","    print(f\"\\nSolution summary:\")\n","    print(f\"  Cancelled flights: {len(solution['cancellations'])}\")\n","    print(f\"  Total delay minutes: {solution['total_delay_minutes']}\")\n","    print(f\"  Number of reassignments: {len(solution['assignments'])}\")\n","\n","# Example usage in a Jupyter notebook:\n","scenario_folder = \"../data/Training/6ac-700-diverse/mixed_high_Scenario_004\"\n","run_exact_solution_and_plot(scenario_folder)\n"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":2}
