{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Path: ../trained_models/dqn/6ac-700-diverse/1025/myopic-91.zip\n",
      "Environment Type: myopic\n",
      "seed: 42\n",
      "Step 0:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.16}}\n",
      "\n",
      "Calculating reward for action: flight 12, aircraft 1\n",
      "  -7800.0 penalty for 156.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  +21.950000000000003 bonus for proactive action (439.0 minutes ahead)\n",
      "  -6.0 penalty for time progression\n",
      "  -100 penalty for tail swap\n",
      "--------------------------------\n",
      "Total reward: -7884.0\n",
      "--------------------------------\n",
      "action index:\n",
      "85\n",
      "action mapped:\n",
      "(12, 1)\n",
      "Action taken: (12, 1), Reward: -7884.0\n",
      "Step 1:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.2001720922527415}}\n",
      "\n",
      "Calculating reward for action: flight 11, aircraft 1\n",
      "  -8200.0 penalty for 164.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  +4.5 bonus for proactive action (90.0 minutes ahead)\n",
      "  -12.0 penalty for time progression\n",
      "  -100 penalty for tail swap\n",
      "--------------------------------\n",
      "Total reward: -8307.5\n",
      "--------------------------------\n",
      "action index:\n",
      "78\n",
      "action mapped:\n",
      "(11, 1)\n",
      "Action taken: (11, 1), Reward: -8307.5\n",
      "Step 2:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.14878806085368568}}\n",
      "\n",
      "Calculating reward for action: flight 5, aircraft 2\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -18.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -18.0\n",
      "--------------------------------\n",
      "action index:\n",
      "37\n",
      "action mapped:\n",
      "(5, 2)\n",
      "Action taken: (5, 2), Reward: -18.0\n",
      "Step 3:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.13348686013113958}}\n",
      "\n",
      "Calculating reward for action: flight 6, aircraft 2\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -24.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -24.0\n",
      "--------------------------------\n",
      "action index:\n",
      "44\n",
      "action mapped:\n",
      "(6, 2)\n",
      "Action taken: (6, 2), Reward: -24.0\n",
      "Step 4:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.11634238404785203}}\n",
      "\n",
      "Calculating reward for action: flight 6, aircraft 2\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -30.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -30.0\n",
      "--------------------------------\n",
      "action index:\n",
      "44\n",
      "action mapped:\n",
      "(6, 2)\n",
      "Action taken: (6, 2), Reward: -30.0\n",
      "Step 5:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.10218260100282008}}\n",
      "\n",
      "Calculating reward for action: flight 6, aircraft 2\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -5000 penalty for 1 new cancelled flights: {8}\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -36.0 penalty for time progression\n",
      "  +30000 final reward for resolving 1 real (non-cancelled) conflicts at scenario end: [11.0]\n",
      "--------------------------------\n",
      "Total reward: 24964.0\n",
      "--------------------------------\n",
      "action index:\n",
      "44\n",
      "action mapped:\n",
      "(6, 2)\n",
      "Action taken: (6, 2), Reward: 24964.0\n",
      "================================================\n",
      "Final state:\n",
      "Total Reward: 8700.5\n",
      "Total Steps: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d2b918935648b68b50b9d9b4b87c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='⬅️', layout=Layout(width='40px'), style=ButtonStyle()), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6ebea3f86846e9bf63d1db82edba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Path: ../trained_models/dqn/6ac-700-diverse/1025/proactive-94.zip\n",
      "Environment Type: proactive\n",
      "seed: 42\n",
      "Step 0:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.16}}\n",
      "\n",
      "Calculating reward for action: flight 11, aircraft 5\n",
      "  -4500.0 penalty for 90.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  +7.5 bonus for proactive action (150.0 minutes ahead)\n",
      "  -6.0 penalty for time progression\n",
      "  -100 penalty for tail swap\n",
      "--------------------------------\n",
      "Total reward: -4598.5\n",
      "--------------------------------\n",
      "action index:\n",
      "82\n",
      "action mapped:\n",
      "(11, 5)\n",
      "Action taken: (11, 5), Reward: -4598.5\n",
      "Step 1:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.175026771938404}}\n",
      "\n",
      "Calculating reward for action: flight 8, aircraft 5\n",
      "  -10450.0 penalty for 209.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  +12.8 bonus for proactive action (256.0 minutes ahead)\n",
      "  -12.0 penalty for time progression\n",
      "  -100 penalty for tail swap\n",
      "--------------------------------\n",
      "Total reward: -10549.2\n",
      "--------------------------------\n",
      "action index:\n",
      "61\n",
      "action mapped:\n",
      "(8, 5)\n",
      "Action taken: (8, 5), Reward: -10549.2\n",
      "Step 2:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.21268070106454048}}\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -18.0 penalty for time progression\n",
      "  +30000 final reward for resolving 1 real (non-cancelled) conflicts at scenario end: [11.0]\n",
      "--------------------------------\n",
      "Total reward: 29982.0\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: 29982.0\n",
      "Step 3:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.2379477516411691}}\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -24.0 penalty for time progression\n",
      "  +30000 final reward for resolving 1 real (non-cancelled) conflicts at scenario end: [11.0]\n",
      "--------------------------------\n",
      "Total reward: 29976.0\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: 29976.0\n",
      "Step 4:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.2178405482256022}}\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -30.0 penalty for time progression\n",
      "  +30000 final reward for resolving 1 real (non-cancelled) conflicts at scenario end: [11.0]\n",
      "--------------------------------\n",
      "Total reward: 29970.0\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: 29970.0\n",
      "Step 5:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.1659069273853302}}\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -36.0 penalty for time progression\n",
      "  +30000 final reward for resolving 1 real (non-cancelled) conflicts at scenario end: [11.0]\n",
      "--------------------------------\n",
      "Total reward: 29964.0\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: 29964.0\n",
      "================================================\n",
      "Final state:\n",
      "Total Reward: 104744.3\n",
      "Total Steps: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9974fa99a374ce8b7f1e9360fb7dd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='⬅️', layout=Layout(width='40px'), style=ButtonStyle()), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda07bd05911400fb21a4d082bc070d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Path: ../trained_models/dqn/6ac-700-diverse/1025/reactive-97.zip\n",
      "Environment Type: reactive\n",
      "seed: 42\n",
      "Step 0:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.16}}\n",
      "*** amount of allowed actions: 1.0\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0 penalty for 0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0.2 penalty for inaction with remaining conflicts\n",
      "  -6.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -6.2\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: -6.2\n",
      "Step 1:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.147303256134373}}\n",
      "*** amount of allowed actions: 1.0\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0 penalty for 0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0.2 penalty for inaction with remaining conflicts\n",
      "  -12.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -12.2\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: -12.2\n",
      "Step 2:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.15449637951859094}}\n",
      "*** amount of allowed actions: 92.0\n",
      "\n",
      "Calculating reward for action: flight 4, aircraft 4\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -5000 penalty for 1 new cancelled flights: {11}\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  +4.5 bonus for proactive action (90.0 minutes ahead)\n",
      "  -18.0 penalty for time progression\n",
      "  -100 penalty for tail swap\n",
      "--------------------------------\n",
      "Total reward: -5113.5\n",
      "--------------------------------\n",
      "action index:\n",
      "32\n",
      "action mapped:\n",
      "(4, 4)\n",
      "Action taken: (4, 4), Reward: -5113.5\n",
      "Step 3:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.1866529641553815}}\n",
      "*** amount of allowed actions: 1.0\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0.2 penalty for inaction with remaining conflicts\n",
      "  -24.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -24.2\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: -24.2\n",
      "Step 4:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.2210751460434407}}\n",
      "*** amount of allowed actions: 1.0\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -0 penalty for 0 new cancelled flights: set()\n",
      "  -0.2 penalty for inaction with remaining conflicts\n",
      "  -30.0 penalty for time progression\n",
      "--------------------------------\n",
      "Total reward: -30.2\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: -30.2\n",
      "Step 5:\n",
      "**updated_alt_aircraft_dict:\n",
      "{'B737#6': {'StartDate': '19/09/24', 'StartTime': '12:09', 'EndDate': '19/09/24', 'EndTime': '19:30', 'Probability': 1.0}, 'B737#3': {'StartDate': '19/09/24', 'StartTime': '10:03', 'EndDate': '19/09/24', 'EndTime': '13:08', 'Probability': 0.25209066346279785}}\n",
      "*** amount of allowed actions: 1.0\n",
      "\n",
      "Calculating reward for action: flight 0, aircraft 0\n",
      "  -0.0 penalty for 0.0 minutes of additional delay (capped at 25000000)\n",
      "  -5000 penalty for 1 new cancelled flights: {8}\n",
      "  -0 penalty for inaction with remaining conflicts\n",
      "  -36.0 penalty for time progression\n",
      "  +0 final reward for resolving 0 real (non-cancelled) conflicts at scenario end: []\n",
      "--------------------------------\n",
      "Total reward: -5036.0\n",
      "--------------------------------\n",
      "action index:\n",
      "0\n",
      "action mapped:\n",
      "(0, 0)\n",
      "Action taken: (0, 0), Reward: -5036.0\n",
      "================================================\n",
      "Final state:\n",
      "Total Reward: -10222.3\n",
      "Total Steps: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fb6e63546442b8965e4ed36e15472d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='⬅️', layout=Layout(width='40px'), style=ButtonStyle()), Button(description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf1f3c1656b49cdaad8eab363ba82d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from src.environment import AircraftDisruptionEnv\n",
    "from scripts.visualizations import StatePlotter\n",
    "from scripts.utils import load_scenario_data\n",
    "from src.config import *\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Image as IPImage\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load the model and run inference\n",
    "def run_inference_dqn(model_path, scenario_folder, env_type, seed, plot_title):\n",
    "    # Load the scenario data\n",
    "    data_dict = load_scenario_data(scenario_folder)\n",
    "\n",
    "    # Extract necessary data for the environment\n",
    "    aircraft_dict = data_dict['aircraft']\n",
    "    flights_dict = data_dict['flights']\n",
    "    rotations_dict = data_dict['rotations']\n",
    "    alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "    config_dict = data_dict['config']\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = AircraftDisruptionEnv(\n",
    "        aircraft_dict, \n",
    "        flights_dict, \n",
    "        rotations_dict, \n",
    "        alt_aircraft_dict, \n",
    "        config_dict,\n",
    "        env_type=env_type\n",
    "    )\n",
    "\n",
    "    # Load the trained model and set the environment\n",
    "    model = DQN.load(model_path)\n",
    "    model.set_env(env)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.policy.set_training_mode(False)\n",
    "    model.exploration_rate = 0.0\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    print(f\"seed: {seed}\")\n",
    "\n",
    "    # Create StatePlotter object for visualizing the environment state\n",
    "    state_plotter = StatePlotter(\n",
    "        aircraft_dict=env.aircraft_dict,\n",
    "        flights_dict=env.flights_dict,\n",
    "        rotations_dict=env.rotations_dict,\n",
    "        alt_aircraft_dict=env.alt_aircraft_dict,\n",
    "        start_datetime=env.start_datetime,\n",
    "        end_datetime=env.end_datetime,\n",
    "        uncertain_breakdowns=env.uncertain_breakdowns,\n",
    "        plot_title=plot_title\n",
    "    )\n",
    "\n",
    "    # Reset the environment for inference\n",
    "    obs, _ = env.reset()\n",
    "    done_flag = False\n",
    "    total_reward = 0\n",
    "    step_num = 0\n",
    "    max_steps = 1000  # Set a maximum number of steps to prevent infinite loops\n",
    "\n",
    "    # List to collect images\n",
    "    plots = []\n",
    "\n",
    "    while not done_flag and step_num < max_steps:\n",
    "        # Visualize the current state\n",
    "        print(f\"Step {step_num}:\")\n",
    "\n",
    "        # Extract necessary information from the environment for plotting\n",
    "        swapped_flights = env.swapped_flights\n",
    "        environment_delayed_flights = env.environment_delayed_flights\n",
    "        current_datetime = env.current_datetime\n",
    "\n",
    "        # Retrieve the updated dictionaries from the environment\n",
    "        updated_flights_dict = env.flights_dict\n",
    "        updated_rotations_dict = env.rotations_dict\n",
    "        updated_alt_aircraft_dict = env.alt_aircraft_dict\n",
    "        print(\"**updated_alt_aircraft_dict:\")\n",
    "        print(updated_alt_aircraft_dict)\n",
    "        cancelled_flights = env.penalized_cancelled_flights\n",
    "\n",
    "        if DEBUG_MODE_VISUALIZATION:\n",
    "            print(\"Flights Dict:\")\n",
    "            print(updated_flights_dict)\n",
    "            print(\"Alt Aircraft Dict:\")\n",
    "            print(updated_alt_aircraft_dict)\n",
    "            print(\"Swapped Flights:\")\n",
    "            print(swapped_flights)\n",
    "            print(\"Environment Delayed Flights:\")\n",
    "            print(environment_delayed_flights)\n",
    "            print(\"Cancelled Flights:\")\n",
    "            print(cancelled_flights)\n",
    "            print(\"Unavailabilities:\")\n",
    "            print(env.alt_aircraft_dict)\n",
    "            print(\"Uncertain Breakdowns:\")\n",
    "            for key, value in env.uncertain_breakdowns.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "            print(\"Current Breakdowns:\")\n",
    "            print(env.current_breakdowns)\n",
    "            print(\"\")\n",
    "\n",
    "        # Update the StatePlotter's dictionaries with the updated ones\n",
    "        state_plotter.alt_aircraft_dict = updated_alt_aircraft_dict\n",
    "        state_plotter.flights_dict = updated_flights_dict\n",
    "        state_plotter.rotations_dict = updated_rotations_dict\n",
    "\n",
    "        if 'reward' not in locals():\n",
    "            reward = 0\n",
    "            action = 0\n",
    "        \n",
    "        # Collect the plot as an image\n",
    "        fig = state_plotter.plot_state(\n",
    "            updated_flights_dict, \n",
    "            swapped_flights, \n",
    "            environment_delayed_flights, \n",
    "            cancelled_flights, \n",
    "            current_datetime, \n",
    "            title_appendix=env_type,\n",
    "            show_plot=False,\n",
    "            reward_and_action=(reward, env.map_index_to_action(action), total_reward)\n",
    "        )\n",
    "        # Make figure taller\n",
    "        # fig.set_figheight(10)\n",
    "        # Convert the figure to an image buffer\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = IPImage(data=buf.read(), format='png', embed=True)\n",
    "        plots.append(img)\n",
    "        plt.close(fig)  # Close the figure to prevent automatic display\n",
    "\n",
    "        # Get the action mask from the environment\n",
    "        action_mask = obs['action_mask']\n",
    "\n",
    "        # Convert observation to float32\n",
    "        obs = {key: np.array(value, dtype=np.float32) for key, value in obs.items()}\n",
    "\n",
    "        # Get the action mask from the observation\n",
    "        action_mask = obs.get('action_mask', None)\n",
    "        if action_mask is None:\n",
    "            raise ValueError(\"Action mask is missing in the observation!\")\n",
    "\n",
    "        # Get the Q-values and apply the action mask\n",
    "        obs_tensor = model.policy.obs_to_tensor(obs)[0]\n",
    "        q_values = model.policy.q_net(obs_tensor).detach().cpu().numpy().squeeze()\n",
    "\n",
    "        # Mask invalid actions by setting their Q-values to -inf\n",
    "        masked_q_values = q_values.copy()\n",
    "        masked_q_values[action_mask == 0] = -np.inf\n",
    "\n",
    "        if env_type == 'reactive':\n",
    "            print(f\"*** amount of allowed actions: {np.sum(action_mask)}\")\n",
    "        # Predict the action using the masked Q-values\n",
    "        action = np.argmax(masked_q_values)\n",
    "\n",
    "        # Verify if the action is valid\n",
    "        if action_mask[action] == 0:\n",
    "            raise ValueError(f\"Invalid action selected by the model: {action}\")\n",
    "\n",
    "        # Take action in the environment\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Accumulate the reward\n",
    "        total_reward += reward\n",
    "\n",
    "        action_mapped = env.map_index_to_action(action)\n",
    "        print(\"action index:\")\n",
    "        print(action)\n",
    "        print(\"action mapped:\")\n",
    "        print(action_mapped)\n",
    "        print(f\"Action taken: {action_mapped}, Reward: {reward}\")\n",
    "\n",
    "        # Combine terminated and truncated flags\n",
    "        done_flag = terminated or truncated\n",
    "\n",
    "        step_num += 1\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"Final state:\")\n",
    "\n",
    "    current_datetime += timedelta(hours=TIMESTEP_HOURS)\n",
    "\n",
    "    # Plot the final state and collect it\n",
    "    fig = state_plotter.plot_state(\n",
    "        updated_flights_dict, \n",
    "        swapped_flights, \n",
    "        environment_delayed_flights, \n",
    "        cancelled_flights, \n",
    "        current_datetime, \n",
    "        title_appendix=env_type,\n",
    "        show_plot=False,\n",
    "        reward_and_action=(reward, env.map_index_to_action(action), total_reward)\n",
    "    )\n",
    "    # Make figure taller\n",
    "    # fig.set_figheight(12)\n",
    "    # Convert the figure to an image buffer\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = IPImage(data=buf.read(), format='png', embed=True)\n",
    "    plots.append(img)\n",
    "    plt.close(fig)  # Close the figure to prevent automatic display\n",
    "\n",
    "    print(f\"Total Reward: {total_reward}\")\n",
    "    print(f\"Total Steps: {step_num}\")\n",
    "\n",
    "    # Create an interactive slider to display the plots\n",
    "    def update_plot(index):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(plots[index])\n",
    "\n",
    "    slider = widgets.IntSlider(\n",
    "        value=0, min=0, max=len(plots)-1, step=1, description='Step:'\n",
    "    )\n",
    "    output = widgets.Output()\n",
    "\n",
    "    slider.observe(lambda change: update_plot(change['new']), names='value')\n",
    "\n",
    "    # Create buttons for navigation\n",
    "    prev_button = widgets.Button(description='⬅️', layout=widgets.Layout(width='40px'))\n",
    "    next_button = widgets.Button(description='➡️', layout=widgets.Layout(width='40px'))\n",
    "    \n",
    "    def on_prev_button_clicked(b):\n",
    "        slider.value = max(0, slider.value - 1)\n",
    "    \n",
    "    def on_next_button_clicked(b):\n",
    "        slider.value = min(len(plots)-1, slider.value + 1)\n",
    "    \n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    \n",
    "    # Create a horizontal box to hold the navigation controls\n",
    "    navigation = widgets.HBox([prev_button, next_button, slider])\n",
    "    \n",
    "    # Display the initial plot\n",
    "    update_plot(0)\n",
    "    \n",
    "    # Display the navigation controls and output\n",
    "    display(navigation, output)\n",
    "\n",
    "    return total_reward, step_num\n",
    "\n",
    "\n",
    "seed = 42\n",
    "\n",
    "SCENARIO_FOLDER = \"../data/Testing/6ac-700-diverse/deterministic_na_Scenario_003\"\n",
    "\n",
    "# SCENARIO_FOLDER = \"../data/RESULTS/t_001\"\n",
    "SCENARIO_FOLDER = \"../data/ROADEF/A03_6088570\"\n",
    "\n",
    "\n",
    "SCENARIO_FOLDER = \"../data/Testing/6ac-700-diverse/mixed_low_Scenario_061\"\n",
    "\n",
    "models = [\n",
    "    # (\"../trained_models/dqn/6ac-700-diverse/1023/proactive-93.zip\", \"proactive\", \"DQN Proactive-U\"), \n",
    "    # (\"../trained_models/dqn/6ac-700-diverse/1024/myopic-90.zip\", \"myopic\", \"DQN Proactive-N\"),\n",
    "    # (\"../trained_models/dqn/6ac-700-diverse/1024/reactive-95.zip\", \"reactive\", \"DQN Reactive\"),\n",
    "    # (\"../trained_models/dqn/6ac-100-superdiverse/111/drl-greedy-246.zip\", \"drl-greedy\", \"DQN Greedy-Guided\"),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1025/myopic-91.zip\", \"myopic\", \"DQN Proactive-N\"),\n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1025/proactive-94.zip\", \"proactive\", \"DQN Proactive-U\"), \n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1025/reactive-97.zip\", \"reactive\", \"DQN Reactive\"),\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1023/myopic-89.zip\", \"myopic\"),\n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1023/proactive-93.zip\", \"proactive\"), \n",
    "    (\"../trained_models/dqn/6ac-700-diverse/1023/reactive-96.zip\", \"reactive\"),\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for model in models:\n",
    "    MODEL_PATH = model[0]\n",
    "    env_type = model[1]\n",
    "    plot_title = model[2]\n",
    "    print(\"*****\"*10)\n",
    "    print(f\"Model Path: {MODEL_PATH}\")\n",
    "    print(f\"Environment Type: {env_type}\")\n",
    "    if not os.path.exists(SCENARIO_FOLDER):\n",
    "        raise FileNotFoundError(f\"Scenario folder not found: {SCENARIO_FOLDER}\")\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}\")\n",
    "\n",
    "    # Run the fixed inference loop\n",
    "    run_inference_dqn(MODEL_PATH, SCENARIO_FOLDER, env_type, seed, plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
