{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from scripts.utils import *\n",
    "from scripts.visualizations import *\n",
    "from src.config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scripts.dqn_mask_policy import CustomMaskedDQNPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3000 days of data (10 unique scenarios)\n",
      "Model name: dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-1.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-3.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-2.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-6.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-5.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "checking file: dqn_3000d_10u-4.zip\n",
      " - file starts with dqn_3000d_10u\n",
      "Model will be saved to: ../trained_models/dqn_3000d_10u-7.zip\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.99\n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 32\n",
    "TARGET_UPDATE_INTERVAL = 100\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_MIN = 0.05\n",
    "EPSILON_DECAY_RATE = 0.0005\n",
    "N_EPISODES = 300            # number of episodes PER TRAINING SCENARIO\n",
    "MAX_TIMESTEPS = 500         # maximum number of timesteps per episode (not relevant here)\n",
    "NEURAL_NET_STRUCTURE = dict(net_arch=[256, 256*4, 256])  \n",
    "TRAINING_FOLDERS_PATH = '../data/Training'\n",
    "\n",
    "# Verify folders exists\n",
    "if not os.path.exists(TRAINING_FOLDERS_PATH):\n",
    "    raise FileNotFoundError(f'Training folder not found at {TRAINING_FOLDERS_PATH}')\n",
    "\n",
    "# print all folders in the training folder\n",
    "training_folders = []\n",
    "for folder in os.listdir(TRAINING_FOLDERS_PATH):\n",
    "    if os.path.isdir(os.path.join(TRAINING_FOLDERS_PATH, folder)):\n",
    "        training_folders.append(folder)\n",
    "\n",
    "num_days_trained_on = N_EPISODES * len(training_folders)\n",
    "print(f'Training on {num_days_trained_on} days of data ({len(training_folders)} unique scenarios)')\n",
    "\n",
    "model_name = 'dqn_' + str(num_days_trained_on) + \"d_\" + str(len(training_folders)) + \"u\"\n",
    "print('Model name:', model_name)\n",
    "model_version = get_model_version(model_name)\n",
    "MODEL_SAVE_PATH = '../trained_models/' + model_name + '-' + model_version + '.zip'\n",
    "\n",
    "print('Model will be saved to:', MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.environment import AircraftDisruptionEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scenario_data(scenario_folder):\n",
    "    file_keys = ['aircraft', 'airports', 'alt_aircraft', 'alt_airports', 'alt_flights', 'config', 'dist', 'flights', 'itineraries', 'position', 'rotations']\n",
    "    file_paths = {key: os.path.join(scenario_folder, f\"{key}.csv\") for key in file_keys}\n",
    "\n",
    "    data_dict = {}\n",
    "    file_parsing_functions = {\n",
    "        'config': FileParsers.parse_config,\n",
    "        'airports': FileParsers.parse_airports,\n",
    "        'dist': FileParsers.parse_dist,\n",
    "        'flights': FileParsers.parse_flights,\n",
    "        'aircraft': FileParsers.parse_aircraft,\n",
    "        'rotations': FileParsers.parse_rotations,\n",
    "        'itineraries': FileParsers.parse_itineraries,\n",
    "        'position': FileParsers.parse_position,\n",
    "        'alt_flights': FileParsers.parse_alt_flights,\n",
    "        'alt_aircraft': FileParsers.parse_alt_aircraft,\n",
    "        'alt_airports': FileParsers.parse_alt_airports\n",
    "    }\n",
    "\n",
    "    # Iterate over each file and process it using the correct parsing function\n",
    "    for file_type, file_path in file_paths.items():\n",
    "        file_lines = read_csv_with_comments(file_path)\n",
    "        if file_lines:\n",
    "            parse_function = file_parsing_functions.get(file_type)\n",
    "            if parse_function:\n",
    "                parsed_data = parse_function(file_lines)\n",
    "                data_dict[file_type] = parsed_data\n",
    "            else:\n",
    "                print(f\"No parser available for file type: {file_type}\")\n",
    "        else:\n",
    "            data_dict[file_type] = None\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "now doing init of custom policy\n",
      "now doing init of custom extractor\n",
      "now doing init of custom extractor\n",
      "Using custom feature extractor: None\n",
      "Using policy: CustomMaskedDQNPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): MaskedMlpExtractor(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=11, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): MaskedMlpExtractor(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=11, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using feature extractor: None\n",
      "Using policy: CustomMaskedDQNPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): MaskedMlpExtractor(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=11, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): MaskedMlpExtractor(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=11, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=11, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using feature extractor: None\n",
      "Observation after reset: [[[0.000e+00 9.600e+02 1.600e+01       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [1.000e+00       nan       nan 1.000e+00 2.550e+02 4.030e+02 2.000e+00\n",
      "   4.110e+02 4.830e+02 3.000e+00 5.010e+02 7.930e+02 4.000e+00 9.260e+02\n",
      "   1.090e+03       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [2.000e+00       nan       nan 1.100e+01 7.500e+01 1.590e+02 1.200e+01\n",
      "   2.180e+02 3.820e+02 1.300e+01 5.550e+02 8.290e+02 1.400e+01 8.300e+02\n",
      "   1.045e+03       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [3.000e+00       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [4.000e+00       nan       nan 1.900e+01 3.150e+02 5.070e+02 2.000e+01\n",
      "   6.080e+02 7.670e+02 2.100e+01 8.560e+02 1.117e+03       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [5.000e+00       nan       nan 5.000e+00 2.400e+02 4.450e+02 6.000e+00\n",
      "   4.600e+02 7.520e+02 7.000e+00 8.540e+02 1.113e+03       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [6.000e+00       nan       nan 8.000e+00 1.350e+02 4.040e+02 9.000e+00\n",
      "   5.420e+02 6.700e+02 1.000e+01 7.350e+02 9.720e+02       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [7.000e+00 6.500e+01 5.240e+02 1.600e+01 2.700e+02 4.140e+02 1.700e+01\n",
      "   5.050e+02 6.070e+02 1.800e+01 7.420e+02 9.800e+02       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [8.000e+00       nan       nan 2.200e+01 1.350e+02 3.530e+02 2.300e+01\n",
      "   3.680e+02 4.370e+02 2.400e+01 5.510e+02 8.020e+02 2.500e+01 8.480e+02\n",
      "   9.680e+02       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [9.000e+00       nan       nan 2.600e+01 2.100e+02 3.690e+02 2.700e+01\n",
      "   4.760e+02 6.770e+02 2.800e+01 8.500e+02 1.058e+03       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]\n",
      "  [1.000e+01       nan       nan 2.900e+01 3.300e+02 5.170e+02 3.000e+01\n",
      "   6.230e+02 7.020e+02 3.100e+01 7.650e+02 9.300e+02       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan       nan       nan\n",
      "         nan       nan       nan       nan       nan]]]\n",
      "possible actions:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Original Observations in Forward Pass: tensor([[[0.0000e+00, 9.6000e+02, 1.6000e+01,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [1.0000e+00,        nan,        nan, 1.0000e+00, 2.5500e+02,\n",
      "          4.0300e+02, 2.0000e+00, 4.1100e+02, 4.8300e+02, 3.0000e+00,\n",
      "          5.0100e+02, 7.9300e+02, 4.0000e+00, 9.2600e+02, 1.0900e+03,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [2.0000e+00,        nan,        nan, 1.1000e+01, 7.5000e+01,\n",
      "          1.5900e+02, 1.2000e+01, 2.1800e+02, 3.8200e+02, 1.3000e+01,\n",
      "          5.5500e+02, 8.2900e+02, 1.4000e+01, 8.3000e+02, 1.0450e+03,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [3.0000e+00,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [4.0000e+00,        nan,        nan, 1.9000e+01, 3.1500e+02,\n",
      "          5.0700e+02, 2.0000e+01, 6.0800e+02, 7.6700e+02, 2.1000e+01,\n",
      "          8.5600e+02, 1.1170e+03,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [5.0000e+00,        nan,        nan, 5.0000e+00, 2.4000e+02,\n",
      "          4.4500e+02, 6.0000e+00, 4.6000e+02, 7.5200e+02, 7.0000e+00,\n",
      "          8.5400e+02, 1.1130e+03,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [6.0000e+00,        nan,        nan, 8.0000e+00, 1.3500e+02,\n",
      "          4.0400e+02, 9.0000e+00, 5.4200e+02, 6.7000e+02, 1.0000e+01,\n",
      "          7.3500e+02, 9.7200e+02,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [7.0000e+00, 6.5000e+01, 5.2400e+02, 1.6000e+01, 2.7000e+02,\n",
      "          4.1400e+02, 1.7000e+01, 5.0500e+02, 6.0700e+02, 1.8000e+01,\n",
      "          7.4200e+02, 9.8000e+02,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [8.0000e+00,        nan,        nan, 2.2000e+01, 1.3500e+02,\n",
      "          3.5300e+02, 2.3000e+01, 3.6800e+02, 4.3700e+02, 2.4000e+01,\n",
      "          5.5100e+02, 8.0200e+02, 2.5000e+01, 8.4800e+02, 9.6800e+02,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [9.0000e+00,        nan,        nan, 2.6000e+01, 2.1000e+02,\n",
      "          3.6900e+02, 2.7000e+01, 4.7600e+02, 6.7700e+02, 2.8000e+01,\n",
      "          8.5000e+02, 1.0580e+03,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan],\n",
      "         [1.0000e+01,        nan,        nan, 2.9000e+01, 3.3000e+02,\n",
      "          5.1700e+02, 3.0000e+01, 6.2300e+02, 7.0200e+02, 3.1000e+01,\n",
      "          7.6500e+02, 9.3000e+02,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan,        nan,        nan,\n",
      "                 nan,        nan,        nan]]])\n",
      "Masked Observations in Forward Pass: tensor([[[0.0000e+00, 9.6000e+02, 1.6000e+01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 2.5500e+02,\n",
      "          4.0300e+02, 2.0000e+00, 4.1100e+02, 4.8300e+02, 3.0000e+00,\n",
      "          5.0100e+02, 7.9300e+02, 4.0000e+00, 9.2600e+02, 1.0900e+03,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.0000e+00, 0.0000e+00, 0.0000e+00, 1.1000e+01, 7.5000e+01,\n",
      "          1.5900e+02, 1.2000e+01, 2.1800e+02, 3.8200e+02, 1.3000e+01,\n",
      "          5.5500e+02, 8.2900e+02, 1.4000e+01, 8.3000e+02, 1.0450e+03,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.0000e+00, 0.0000e+00, 0.0000e+00, 1.9000e+01, 3.1500e+02,\n",
      "          5.0700e+02, 2.0000e+01, 6.0800e+02, 7.6700e+02, 2.1000e+01,\n",
      "          8.5600e+02, 1.1170e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00, 2.4000e+02,\n",
      "          4.4500e+02, 6.0000e+00, 4.6000e+02, 7.5200e+02, 7.0000e+00,\n",
      "          8.5400e+02, 1.1130e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [6.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+00, 1.3500e+02,\n",
      "          4.0400e+02, 9.0000e+00, 5.4200e+02, 6.7000e+02, 1.0000e+01,\n",
      "          7.3500e+02, 9.7200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [7.0000e+00, 6.5000e+01, 5.2400e+02, 1.6000e+01, 2.7000e+02,\n",
      "          4.1400e+02, 1.7000e+01, 5.0500e+02, 6.0700e+02, 1.8000e+01,\n",
      "          7.4200e+02, 9.8000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [8.0000e+00, 0.0000e+00, 0.0000e+00, 2.2000e+01, 1.3500e+02,\n",
      "          3.5300e+02, 2.3000e+01, 3.6800e+02, 4.3700e+02, 2.4000e+01,\n",
      "          5.5100e+02, 8.0200e+02, 2.5000e+01, 8.4800e+02, 9.6800e+02,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [9.0000e+00, 0.0000e+00, 0.0000e+00, 2.6000e+01, 2.1000e+02,\n",
      "          3.6900e+02, 2.7000e+01, 4.7600e+02, 6.7700e+02, 2.8000e+01,\n",
      "          8.5000e+02, 1.0580e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+01, 0.0000e+00, 0.0000e+00, 2.9000e+01, 3.3000e+02,\n",
      "          5.1700e+02, 3.0000e+01, 6.2300e+02, 7.0200e+02, 3.1000e+01,\n",
      "          7.6500e+02, 9.3000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (11x33 and 11x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(MODEL_SAVE_PATH)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Run the training process\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mtrain_dqn_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m, in \u001b[0;36mtrain_dqn_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m timesteps \u001b[38;5;241m<\u001b[39m MAX_TIMESTEPS:\n\u001b[1;32m     61\u001b[0m     \n\u001b[1;32m     62\u001b[0m     \n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Print all possible actions in a list in one line\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpossible actions: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn)))\n\u001b[0;32m---> 67\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen action: \u001b[39m\u001b[38;5;124m\"\u001b[39m, action)\n\u001b[1;32m     71\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mq_net(th\u001b[38;5;241m.\u001b[39mtensor(obs, dtype\u001b[38;5;241m=\u001b[39mth\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:255\u001b[0m, in \u001b[0;36mDQN.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    253\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     action, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action, state\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[1;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/dqn/policies.py:184\u001b[0m, in \u001b[0;36mDQNPolicy._predict\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/dqn/policies.py:69\u001b[0m, in \u001b[0;36mQNetwork._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 69\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Greedy action\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     action \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/dqn/policies.py:66\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: PyTorchObs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    Predict the q-values.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    :param obs: Observation\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    :return: The estimated Q-Value for each action.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Home/Studie/MSc Aerospace Engineering/_MSc Thesis Boeing/_GithHub Repos/Boeing-ADM-DRL-Github/scripts/dqn_mask_policy.py:37\u001b[0m, in \u001b[0;36mMaskedMlpExtractor.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasked Observations in Forward Pass:\u001b[39m\u001b[38;5;124m\"\u001b[39m, masked_obs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Forward pass through the network after masking\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/thesis_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (11x33 and 11x128)"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "\n",
    "\n",
    "\n",
    "def train_dqn_agent():\n",
    "    # List all the scenario folders in Data/Training\n",
    "    scenario_folders = [os.path.join(TRAINING_FOLDERS_PATH, folder) for folder in os.listdir(TRAINING_FOLDERS_PATH) if os.path.isdir(os.path.join(TRAINING_FOLDERS_PATH, folder))]\n",
    "    \n",
    "    total_timesteps = 0\n",
    "    epsilon = EPSILON_START\n",
    "\n",
    "    # Training loop over the number of episodes\n",
    "    for episode in range(N_EPISODES):\n",
    "        # Cycle through all the scenario folders\n",
    "        for scenario_folder in scenario_folders:\n",
    "            # Load the data for the current scenario\n",
    "            data_dict = load_scenario_data(scenario_folder)\n",
    "\n",
    "            # Extract necessary data for the environment\n",
    "            aircraft_dict = data_dict['aircraft']\n",
    "            flights_dict = data_dict['flights']\n",
    "            rotations_dict = data_dict['rotations']\n",
    "            alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "            config_dict = data_dict['config']\n",
    "\n",
    "            # Initialize the environment with the current scenario\n",
    "            env = AircraftDisruptionEnv(aircraft_dict, flights_dict, rotations_dict, alt_aircraft_dict, config_dict)\n",
    "            env = DummyVecEnv([lambda: env])\n",
    "\n",
    "            # Initialize the DQN model with the custom policy and feature extractor\n",
    "            model = DQN(\n",
    "                policy=CustomMaskedDQNPolicy,\n",
    "                env=env,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                gamma=GAMMA,\n",
    "                buffer_size=BUFFER_SIZE,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                target_update_interval=TARGET_UPDATE_INTERVAL,\n",
    "                verbose=1,\n",
    "                policy_kwargs={\"features_extractor_kwargs\": {\"features_dim\": 256}}  # Still pass this in model initialization\n",
    "            )\n",
    "\n",
    "\n",
    "            print(f\"Using policy: {model.policy}\")\n",
    "            print(f\"Using feature extractor: {model.policy.features_extractor}\")\n",
    "\n",
    "\n",
    "            # Verify the policy and feature extractor\n",
    "            print(f\"Using policy: {model.policy}\")\n",
    "            print(f\"Using feature extractor: {model.policy.features_extractor}\")\n",
    "\n",
    "            # Reset the environment\n",
    "            obs = env.reset()\n",
    "            print(f\"Observation after reset: {obs}\")\n",
    "\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            timesteps = 0\n",
    "\n",
    "            while not done and timesteps < MAX_TIMESTEPS:\n",
    "                \n",
    "                \n",
    "\n",
    "                # Print all possible actions in a list in one line\n",
    "                print(\"possible actions: \", list(range(env.action_space.n)))\n",
    "\n",
    "                action = model.predict(obs, deterministic=False)[0]\n",
    "\n",
    "                print(\"chosen action: \", action)\n",
    "\n",
    "                q_values = model.policy.q_net(th.tensor(obs, dtype=th.float32).to(model.device)).detach().cpu().numpy()\n",
    "                print(\"Q-values: \", q_values)\n",
    "\n",
    "                # Step the environment\n",
    "                obs, reward, done, info = env.step(action)\n",
    "\n",
    "                # Accumulate the reward\n",
    "                total_reward += reward\n",
    "\n",
    "                # Update epsilon (exploration rate)\n",
    "                epsilon = max(EPSILON_MIN, epsilon - EPSILON_DECAY_RATE)\n",
    "\n",
    "                timesteps += 1\n",
    "                total_timesteps += 1\n",
    "\n",
    "            # Store the total reward for the episode with the scenario specified\n",
    "            rewards.append((episode, scenario_folder, total_reward))\n",
    "            \n",
    "            print(f\"Episode {episode}, Scenario {scenario_folder}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "\n",
    "# Run the training process\n",
    "train_dqn_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(rewards))\n",
    "\n",
    "avg_rewards = []\n",
    "\n",
    "# avg_rewards contains N_EPISODES elements, each element is the average reward for a given iteration of the ten scenarios\n",
    "for i in range(0, len(rewards), 10):\n",
    "    avg_rewards.append(np.mean([reward for _, _, reward in rewards[i:i+10]]))\n",
    "    \n",
    "# Plot the average rewards over the episodes\n",
    "plt.plot(range(N_EPISODES), avg_rewards)\n",
    "plt.xlabel('Batch of Episodes')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.title(f'Average Reward per batch of {num_days_trained_on} episodes')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
