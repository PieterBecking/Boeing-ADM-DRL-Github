{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Good: </b>Scenario analysis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario ID: 2\n",
      "Data Folder: ../data/TEMP/6ac-700-diverse/\n",
      "                          Scenario  ScenarioSlack  FullyDisruptedCount  \\\n",
      "0    deterministic_na_Scenario_001       0.456566                    2   \n",
      "1    deterministic_na_Scenario_002       0.431838                    2   \n",
      "2    deterministic_na_Scenario_003       0.404209                    2   \n",
      "3    deterministic_na_Scenario_004       0.407562                    2   \n",
      "4    deterministic_na_Scenario_005       0.441667                    2   \n",
      "..                             ...            ...                  ...   \n",
      "695        mixed_high_Scenario_096       0.342424                    1   \n",
      "696        mixed_high_Scenario_097       0.420000                    1   \n",
      "697        mixed_high_Scenario_098       0.406130                    1   \n",
      "698        mixed_high_Scenario_099       0.422569                    1   \n",
      "699        mixed_high_Scenario_100       0.421732                    1   \n",
      "\n",
      "     UncertainCount  AvgAircraftProbability  AvgUncertaintyProbability  \n",
      "0                 0                0.333333                   0.000000  \n",
      "1                 0                0.333333                   0.000000  \n",
      "2                 0                0.333333                   0.000000  \n",
      "3                 0                0.333333                   0.000000  \n",
      "4                 0                0.333333                   0.000000  \n",
      "..              ...                     ...                        ...  \n",
      "695               1                0.280136                   0.680813  \n",
      "696               1                0.293844                   0.763064  \n",
      "697               1                0.273617                   0.641699  \n",
      "698               1                0.279241                   0.675449  \n",
      "699               1                0.310900                   0.865400  \n",
      "\n",
      "[700 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "def time_to_minutes(t):\n",
    "    h, m = map(int, t.split(':'))\n",
    "    return h * 60 + m\n",
    "\n",
    "\n",
    "def calculate_slack_for_scenario(scenario_data):\n",
    "    \"\"\"\n",
    "    Calculate the slack metric for the given scenario.\n",
    "    \n",
    "    Slack is defined as:\n",
    "        Slack = 1 - (total flight minutes in recovery period / total recovery period aircraft-minutes)\n",
    "    \n",
    "    A slack of 1 means no flights during recovery period.\n",
    "    A slack of 0 means flights occupy the entire recovery period.\n",
    "    \"\"\"\n",
    "    def time_to_minutes(timestr):\n",
    "        # timestr format: \"HH:MM\"\n",
    "        hh, mm = timestr.split(\":\")\n",
    "        return int(hh) * 60 + int(mm)\n",
    "    \n",
    "    # Extract scenario start/end times\n",
    "    # We assume the same date for start and end for simplicity.\n",
    "    recovery_start_time_str = scenario_data[\"recovery_start_time\"]  \n",
    "    recovery_end_time_str = scenario_data[\"recovery_end_time\"]      \n",
    "    \n",
    "    recovery_start_minutes = time_to_minutes(recovery_start_time_str)\n",
    "    recovery_end_minutes = time_to_minutes(recovery_end_time_str)\n",
    "    total_recovery_period_minutes = recovery_end_minutes - recovery_start_minutes\n",
    "    \n",
    "    total_aircraft = scenario_data[\"total_aircraft\"]\n",
    "    \n",
    "    # Calculate total flight minutes within the recovery period\n",
    "    flights = scenario_data[\"flights\"]\n",
    "    total_flight_minutes_in_recovery = 0\n",
    "    \n",
    "    for flight_id, flight_data in flights.items():\n",
    "        dep_time_str = flight_data[\"DepTime\"]  \n",
    "        arr_time_str = flight_data[\"ArrTime\"] \n",
    "        \n",
    "        dep_minutes = time_to_minutes(dep_time_str)\n",
    "        arr_minutes = time_to_minutes(arr_time_str)\n",
    "        \n",
    "        \n",
    "        overlap_start = max(dep_minutes, recovery_start_minutes)\n",
    "        overlap_end = min(arr_minutes, recovery_end_minutes)\n",
    "        \n",
    "        if overlap_end > overlap_start:\n",
    "            flight_overlap = overlap_end - overlap_start\n",
    "        else:\n",
    "            flight_overlap = 0\n",
    "        \n",
    "        total_flight_minutes_in_recovery += flight_overlap\n",
    "    \n",
    "    # Calculate total aircraft-minutes available during the recovery period\n",
    "    total_recovery_aircraft_minutes = total_recovery_period_minutes * total_aircraft\n",
    "    \n",
    "    # Slack calculation\n",
    "    if total_recovery_aircraft_minutes == 0:\n",
    "        slack = 1.0\n",
    "    else:\n",
    "        slack = 1 - (total_flight_minutes_in_recovery / total_recovery_aircraft_minutes)\n",
    "    \n",
    "    return slack\n",
    "\n",
    "\n",
    "def extract_disruption_stats(scenario_data):\n",
    "    \"\"\"\n",
    "    Extract disruption statistics:\n",
    "    - Count of fully disrupted (prob = 1.0)\n",
    "    - Count of uncertain disruptions (0 < prob < 1.0)\n",
    "    - Average probability across all aircraft (where an aircraft's probability is the max disruption probability it faces, \n",
    "      with 1.0 for fully disrupted and 0.0 if no disruption)\n",
    "    - Average uncertainty probability (average of all disruptions where 0<prob<1.0, excluding 0 and 1)\n",
    "    \"\"\"\n",
    "    disruptions_info = scenario_data.get('disruptions', {})\n",
    "    disruptions_list = disruptions_info.get('disruptions', [])\n",
    "    total_aircraft = disruptions_info.get('total_aircraft', 0)\n",
    "\n",
    "    if total_aircraft == 0:\n",
    "        # No aircraft or no disruptions\n",
    "        return 0, 0, 0.0, 0.0\n",
    "\n",
    "    fully_disrupted_count = sum(1 for d in disruptions_list if d.get('probability', 0.0) == 1.0)\n",
    "    uncertain_disruptions = [d for d in disruptions_list if 0.0 < d.get('probability', 0.0) < 1.0]\n",
    "    uncertain_count = len(uncertain_disruptions)\n",
    "\n",
    "    aircraft_ids = scenario_data.get('aircraft_ids', [])\n",
    "    ac_prob_map = {ac: 0.0 for ac in aircraft_ids}  \n",
    "    \n",
    "    for d in disruptions_list:\n",
    "        ac_id = d.get('aircraft_id')\n",
    "        p = d.get('probability', 0.0)\n",
    "        # Keep the max probability for that aircraft\n",
    "        if ac_id in ac_prob_map:\n",
    "            ac_prob_map[ac_id] = max(ac_prob_map[ac_id], p)\n",
    "\n",
    "    avg_ac_prob = sum(ac_prob_map.values()) / total_aircraft if total_aircraft > 0 else 0.0\n",
    "\n",
    "    # Average uncertainty probability (only consider disruptions where 0<prob<1)\n",
    "    if len(uncertain_disruptions) > 0:\n",
    "        avg_uncertainty_prob = np.mean([d['probability'] for d in uncertain_disruptions])\n",
    "    else:\n",
    "        avg_uncertainty_prob = 0.0\n",
    "\n",
    "    return fully_disrupted_count, uncertain_count, avg_ac_prob, avg_uncertainty_prob\n",
    "\n",
    "# Path to the scenarios folder\n",
    "scenario_folder_path = \"../logs/scenarios/\"\n",
    "latest_folder = max(\n",
    "    [f for f in os.listdir(scenario_folder_path) if f.startswith(\"scenario_folder_\")],\n",
    "    key=lambda x: int(x.split('_')[-1].replace('.json', ''))\n",
    ")\n",
    "\n",
    "latest_folder = \"scenario_folder_scenario_2.json\"\n",
    "\n",
    "file_path = os.path.join(scenario_folder_path, latest_folder)\n",
    "\n",
    "# Extract scenario ID\n",
    "scenario_id = file_path.split('_')[-1].split('.')[0]\n",
    "print(f\"Scenario ID: {scenario_id}\")\n",
    "\n",
    "# Load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the scenarios from the JSON data\n",
    "scenarios = data['outputs']\n",
    "\n",
    "\n",
    "# Extract the data_folder (not strictly necessary for slack calculation, but we print it for context)\n",
    "data_folder = data['data_folder']\n",
    "print(f\"Data Folder: {data_folder}\")\n",
    "\n",
    "# Calculate slack and disruption stats for each scenario and store in a list of dicts\n",
    "results = []\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    scenario_slack = calculate_slack_for_scenario(scenario_data)\n",
    "    fully_disrupted_count, uncertain_count, avg_ac_prob, avg_uncertain_prob = extract_disruption_stats(scenario_data)\n",
    "    results.append({\n",
    "        \"Scenario\": scenario_name,\n",
    "        \"ScenarioSlack\": scenario_slack,\n",
    "        \"FullyDisruptedCount\": fully_disrupted_count,\n",
    "        \"UncertainCount\": uncertain_count,\n",
    "        \"AvgAircraftProbability\": avg_ac_prob,\n",
    "        \"AvgUncertaintyProbability\": avg_uncertain_prob\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "scenarios_df = pd.DataFrame(results)\n",
    "print(scenarios_df)\n",
    "\n",
    "# Save the slack results to CSV\n",
    "# output_file = os.path.join(scenario_folder_path, f\"scenario_slack_metrics_{scenario_id}.csv\")\n",
    "# scenarios_df.to_csv(output_file, index=False)\n",
    "# print(f\"Slack metrics saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Good: </b>Inferencing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on data folder: ../data/TEMP/6ac-700-diverse/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from src.environment import AircraftDisruptionEnv\n",
    "from scripts.utils import load_scenario_data, NumpyEncoder, get_training_metadata\n",
    "from scripts.logger import create_new_id, log_inference_metadata, find_corresponding_training_id, convert_to_serializable\n",
    "\n",
    "def run_inference_dqn_single(model_path, scenario_folder, env_type, seed):\n",
    "    \"\"\"\n",
    "    Runs inference on a single scenario and returns the total reward.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    data_dict = load_scenario_data(scenario_folder)\n",
    "    aircraft_dict = data_dict['aircraft']\n",
    "    flights_dict = data_dict['flights']\n",
    "    rotations_dict = data_dict['rotations']\n",
    "    alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "    config_dict = data_dict['config']\n",
    "\n",
    "    env = AircraftDisruptionEnv(\n",
    "        aircraft_dict, flights_dict, rotations_dict, alt_aircraft_dict, config_dict, env_type=env_type\n",
    "    )\n",
    "\n",
    "    model = DQN.load(model_path)\n",
    "    model.set_env(env)\n",
    "    model.policy.set_training_mode(False)\n",
    "    model.exploration_rate = 0.0\n",
    "\n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    done_flag = False\n",
    "    total_reward = 0\n",
    "    step_num = 0\n",
    "    max_steps = 1000\n",
    "\n",
    "    while not done_flag and step_num < max_steps:\n",
    "        action_mask = obs['action_mask']\n",
    "        obs = {key: np.array(value, dtype=np.float32) for key, value in obs.items()}\n",
    "        obs_tensor = model.policy.obs_to_tensor(obs)[0]\n",
    "        q_values = model.policy.q_net(obs_tensor).detach().cpu().numpy().squeeze()\n",
    "\n",
    "        masked_q_values = q_values.copy()\n",
    "        masked_q_values[action_mask == 0] = -np.inf\n",
    "\n",
    "        # If no valid actions remain, break out\n",
    "        if np.all(np.isinf(masked_q_values)):\n",
    "            break\n",
    "\n",
    "        action = np.argmax(masked_q_values)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        done_flag = terminated or truncated\n",
    "        step_num += 1\n",
    "\n",
    "    total_delays = env.scenario_wide_delay_minutes\n",
    "    total_cancelled_flights = env.scenario_wide_cancelled_flights\n",
    "    end_time = time.time()\n",
    "    scenario_time = end_time - start_time\n",
    "    scenario_steps = env.scenario_wide_steps\n",
    "    scenario_resolved_conflicts = env.scenario_wide_resolved_conflicts\n",
    "    solution_slack = env.scenario_wide_solution_slack\n",
    "    scenario_wide_tail_swaps = env.scenario_wide_tail_swaps\n",
    "    scenario_wide_actual_disrupted_flights = env.scenario_wide_actual_disrupted_flights\n",
    "    scenario_wide_reward_components = env.scenario_wide_reward_components\n",
    "\n",
    "    return total_reward, total_delays, total_cancelled_flights, scenario_time, scenario_steps, scenario_resolved_conflicts, solution_slack, scenario_wide_tail_swaps, scenario_wide_actual_disrupted_flights, scenario_wide_reward_components\n",
    "\n",
    "def run_inference_on_data_folder(model_paths, data_folder, seeds):\n",
    "    \"\"\"\n",
    "    Runs inference on all scenarios found in 'data_folder', for each model in 'model_paths' and each seed in 'seeds'.\n",
    "\n",
    "    Args:\n",
    "        model_paths (list): List of model paths to run inference with.\n",
    "        data_folder (str): Path to the folder containing scenario subfolders.\n",
    "        env_type (str): Type of environment (\"myopic\", \"proactive\", \"reactive\").\n",
    "        seeds (list): List of seeds for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing scenario, model, seed, and total reward.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify all scenario folders within data_folder\n",
    "    scenario_folders = [\n",
    "        os.path.join(data_folder, folder)\n",
    "        for folder in os.listdir(data_folder)\n",
    "        if os.path.isdir(os.path.join(data_folder, folder))\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for scenario_folder in scenario_folders:\n",
    "        scenario_name = os.path.basename(scenario_folder)\n",
    "        for model_path in model_paths:\n",
    "            for seed in seeds:\n",
    "                # extract env_type from model_path\n",
    "                env_type = model_path.split(\"/\")[-2]\n",
    "                total_reward, total_delays, total_cancelled_flights, scenario_time, scenario_steps, scenario_resolved_conflicts, solution_slack, scenario_wide_tail_swaps, scenario_wide_actual_disrupted_flights, scenario_wide_reward_components = run_inference_dqn_single(model_path, scenario_folder, env_type, seed)\n",
    "                results.append({\n",
    "                    \"Scenario\": scenario_name,\n",
    "                    \"Model\": os.path.basename(model_path),\n",
    "                    \"Seed\": seed,\n",
    "                    \"TotalReward\": total_reward,\n",
    "                    \"TotalDelays\": total_delays,\n",
    "                    \"TotalCancelledFlights\": total_cancelled_flights,\n",
    "                    \"ScenarioTime\": scenario_time,\n",
    "                    \"ScenarioSteps\": scenario_steps,\n",
    "                    \"ScenarioResolvedConflicts\": scenario_resolved_conflicts,\n",
    "                    \"SolutionSlack\": solution_slack,\n",
    "                    \"TailSwaps\": scenario_wide_tail_swaps,\n",
    "                    \"ActualDisruptedFlights\": scenario_wide_actual_disrupted_flights,\n",
    "                    \"Reward_delay_penalty_total\": scenario_wide_reward_components[\"delay_penalty_total\"],\n",
    "                    \"Reward_cancel_penalty\": scenario_wide_reward_components[\"cancel_penalty\"],\n",
    "                    \"Reward_inaction_penalty\": scenario_wide_reward_components[\"inaction_penalty\"],\n",
    "                    \"Reward_proactive_bonus\": scenario_wide_reward_components[\"proactive_bonus\"],\n",
    "                    \"Reward_time_penalty\": scenario_wide_reward_components[\"time_penalty\"],\n",
    "                    \"Reward_final_conflict_resolution_reward\": scenario_wide_reward_components[\"final_conflict_resolution_reward\"]\n",
    "                })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data_folder = data['data_folder']\n",
    "print(f\"inferencing on data folder: {data_folder}\")\n",
    "\n",
    "# Define models and seeds \n",
    "model_paths = [\n",
    "    # \"../trained_models/dqn/6ac-700-diverse/23/proactive-training_33.zip\",\n",
    "    \"../trained_models/dqn/6ac-700-diverse/51/myopic-training_44.zip\",\n",
    "    \"../trained_models/dqn/6ac-700-diverse/51/proactive-training_45.zip\",\n",
    "    \"../trained_models/dqn/6ac-700-diverse/23/reactive-training_39.zip\"\n",
    "]\n",
    "seeds = [25, 26, 27]\n",
    "# approx 1,5min per seed with 3 models\n",
    "\n",
    "results_df = run_inference_on_data_folder(model_paths, data_folder, seeds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Good: </b>Merging scenario data and inference data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge scenario-level info from scenarios_df into results_df\n",
    "merged_df = results_df.merge(scenarios_df, on='Scenario', how='left')\n",
    "\n",
    "print(\"Inference Results (After Merging):\")\n",
    "print(merged_df.head(20))\n",
    "\n",
    "# Save the merged results to CSV\n",
    "merged_output_file = os.path.join(scenario_folder_path, f\"scenario_inference_metrics_{scenario_id}.csv\")\n",
    "merged_df.to_csv(merged_output_file, index=False)\n",
    "print(f\"Inference results with scenario info saved to {merged_output_file}\")\n",
    "\n",
    "# print all column names\n",
    "print(results_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Check: </b>Comparison of Models Across All Scenarios\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison_table = (\n",
    "    merged_df\n",
    "    .groupby('Model')\n",
    "    .agg(\n",
    "        Mean_Reward=('TotalReward', 'mean'),\n",
    "        Mean_Runtime=('ScenarioTime', 'mean'),\n",
    "        Mean_Steps=('ScenarioSteps', 'mean'),\n",
    "        Mean_Delays=('TotalDelays', 'mean'),\n",
    "        Mean_CancelledFlights=('TotalCancelledFlights', 'mean'),\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"Comparison of Models Across All Scenarios:\")\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate average rewards per scenario-model combination first\n",
    "scenario_model_avgs = (\n",
    "    merged_df\n",
    "    .groupby(['Scenario', 'Model'])['TotalReward']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# For each scenario, find best and second best models based on average rewards\n",
    "scenario_rankings = (\n",
    "    scenario_model_avgs\n",
    "    .groupby('Scenario')\n",
    "    .apply(lambda x: pd.Series({\n",
    "        'best_model': x.loc[x['TotalReward'].idxmax(), 'Model'],\n",
    "        'best_reward': x['TotalReward'].max(),\n",
    "        'second_best_reward': x['TotalReward'].nlargest(2).iloc[-1],\n",
    "        'reward_difference': x['TotalReward'].max() - x['TotalReward'].nlargest(2).iloc[-1]\n",
    "    }))\n",
    ")\n",
    "\n",
    "# Sort by reward difference and get top 5\n",
    "top_5_differences = scenario_rankings.nlargest(5, 'reward_difference')\n",
    "\n",
    "print(\"Top 5 scenarios with largest average performance gap between best and second best model:\")\n",
    "for idx, row in top_5_differences.iterrows():\n",
    "    print(f\"\\nScenario: {idx}\")\n",
    "    print(f\"Best performing model: {row['best_model']}\")\n",
    "    print(f\"Average reward difference: {row['reward_difference']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Check: </b>Comparison of Models Across All Scenarios\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Define reward components and their display names\n",
    "reward_components = [\n",
    "    'Reward_delay_penalty_total', \n",
    "    'Reward_cancel_penalty', \n",
    "    'Reward_inaction_penalty', \n",
    "    'Reward_proactive_bonus', \n",
    "    'Reward_time_penalty', \n",
    "    'Reward_final_conflict_resolution_reward'\n",
    "]\n",
    "\n",
    "component_display_names = {\n",
    "    'Reward_delay_penalty_total': 'Delay penalty',\n",
    "    'Reward_cancel_penalty': 'Cancellation penalty', \n",
    "    'Reward_inaction_penalty': 'Inaction penalty',\n",
    "    'Reward_proactive_bonus': 'Proactive bonus',\n",
    "    'Reward_time_penalty': 'Time penalty',\n",
    "    'Reward_final_conflict_resolution_reward': 'Conflict resolution'\n",
    "}\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in merged_df['Model'].unique()\n",
    "}\n",
    "\n",
    "# Melt the DataFrame to reshape it for bar plotting\n",
    "melted_df = merged_df.melt(\n",
    "    id_vars=['Model'], \n",
    "    value_vars=reward_components,\n",
    "    var_name='RewardComponent', \n",
    "    value_name='Reward'\n",
    ")\n",
    "\n",
    "# Map component names to display names\n",
    "melted_df['RewardComponent'] = melted_df['RewardComponent'].map(component_display_names)\n",
    "\n",
    "# Group by Model and RewardComponent to calculate the mean reward values\n",
    "mean_rewards_df = melted_df.groupby(['Model', 'RewardComponent'], as_index=False).mean()\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar plot with custom colors from model_colors\n",
    "sns.barplot(\n",
    "    data=mean_rewards_df,\n",
    "    x='RewardComponent',\n",
    "    y='Reward',\n",
    "    hue='Model',\n",
    "    palette={model: color[0] for model, color in model_colors.items()}\n",
    ")\n",
    "\n",
    "# Adjust plot aesthetics\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Reward components\")\n",
    "plt.ylabel(\"Mean reward\")\n",
    "plt.title(\"Comparison of reward components across models\")\n",
    "plt.legend(title=\"Models\", labels=[color[1] for color in model_colors.values()])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>To Do: </b>Impact of scenario slack - improve windows smoothening\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Define a color map and human-readable labels for the models\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in merged_df['Model'].unique()\n",
    "}\n",
    "\n",
    "# Define the metrics and corresponding y-axis labels\n",
    "metrics = [\n",
    "    (\"TotalDelays\", \"Delays (minutes)\"),\n",
    "    (\"TailSwaps\", \"Tail swaps\"),\n",
    "    (\"TotalCancelledFlights\", \"Cancelled flights\")\n",
    "]\n",
    "\n",
    "# Aggregate data by taking the mean of the numeric metrics for each (Model, ScenarioSlack)\n",
    "agg_df = (\n",
    "    merged_df\n",
    "    .groupby(['Model', 'ScenarioSlack'], as_index=False)[[m[0] for m in metrics]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)\n",
    "\n",
    "# Window size for smoothing (must be odd number)\n",
    "window_size = 10  # Adjust this value to control smoothing amount\n",
    "\n",
    "for i, (metric, ylabel) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot a line for each model\n",
    "    for model_name, (color, label) in model_colors.items():\n",
    "        model_data = agg_df[agg_df['Model'] == model_name].copy()\n",
    "        # Sort by ScenarioSlack for a proper line plot\n",
    "        model_data = model_data.sort_values(by='ScenarioSlack')\n",
    "        \n",
    "        x = model_data['ScenarioSlack']\n",
    "        y = model_data[metric]\n",
    "        \n",
    "        # Only apply smoothing if we have enough data points\n",
    "        if len(y) >= window_size:\n",
    "            y_smoothed = savgol_filter(y, window_size, 2)  # 2 is polynomial order\n",
    "        else:\n",
    "            y_smoothed = y\n",
    "            \n",
    "        ax.plot(\n",
    "            x,\n",
    "            y_smoothed,\n",
    "            label=label, \n",
    "            color=color,\n",
    "            alpha=0.9\n",
    "        )\n",
    "        \n",
    "\n",
    "    \n",
    "    ax.set_xlabel(\"Scenario slack\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(ylabel)\n",
    "    ax.grid(True)\n",
    "\n",
    "# Add a global legend (once for all subplots)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center', bbox_to_anchor=(0.5, -0.03), ncol=3, title=\"Model\", frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.suptitle(\"Impact of scenario slack\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume merged_df already exists and has columns 'Model', 'ScenarioSlack', 'TotalDelays', 'TailSwaps', 'TotalCancelledFlights'.\n",
    "# The code below shows the modification for filtering slack intervals:\n",
    "\n",
    "# Define a color map and human-readable labels for the models\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in merged_df['Model'].unique()\n",
    "}\n",
    "\n",
    "# Define the metrics and corresponding y-axis labels\n",
    "metrics = [\n",
    "    (\"TotalDelays\", \"Delays (minutes)\"),\n",
    "    (\"TailSwaps\", \"Tail swaps\"),\n",
    "    (\"TotalCancelledFlights\", \"Cancelled flights\")\n",
    "]\n",
    "\n",
    "# Create slack buckets of size 0.05\n",
    "bucket_size = 0.025\n",
    "bucket_edges = np.arange(0, 1 + bucket_size, bucket_size)\n",
    "bucket_labels = [f\"{bucket_edges[i]:.2f}-{bucket_edges[i+1]:.2f}\" for i in range(len(bucket_edges)-1)]\n",
    "\n",
    "# Create slack intervals using the defined buckets\n",
    "merged_df['SlackInterval'] = pd.cut(merged_df['ScenarioSlack'], \n",
    "                                    bins=bucket_edges,\n",
    "                                    labels=bucket_labels,\n",
    "                                    include_lowest=True)\n",
    "\n",
    "# Aggregate data by taking the mean of the numeric metrics for each (Model, SlackInterval)\n",
    "agg_df = (\n",
    "    merged_df\n",
    "    .groupby(['Model', 'SlackInterval'], as_index=False)[[m[0] for m in metrics]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Remove rows where SlackInterval has no actual values\n",
    "agg_df = agg_df.dropna(subset=['SlackInterval'])\n",
    "\n",
    "# Define the display range for slack values\n",
    "display_range = (0.25, 0.55)  # for example, only show intervals between 0.2 and 0.6\n",
    "\n",
    "# Filter agg_df to only include intervals that lie fully within display_range\n",
    "def interval_in_range(interval_label, low, high):\n",
    "    start_str, end_str = interval_label.split('-')\n",
    "    start_val = float(start_str)\n",
    "    end_val = float(end_str)\n",
    "    # Check if the entire interval lies within the specified range\n",
    "    return start_val >= low and end_val <= high\n",
    "\n",
    "agg_df = agg_df[agg_df['SlackInterval'].apply(lambda x: interval_in_range(x, display_range[0], display_range[1]))]\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)\n",
    "\n",
    "bar_width = 0.25\n",
    "\n",
    "# Get only the filtered slack intervals\n",
    "slack_intervals = sorted(agg_df['SlackInterval'].unique())\n",
    "x = np.arange(len(slack_intervals))\n",
    "\n",
    "for i, (metric, ylabel) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot bars for each model\n",
    "    for j, (model_name, (color, label)) in enumerate(model_colors.items()):\n",
    "        model_data = agg_df[agg_df['Model'] == model_name]\n",
    "        \n",
    "        # Align model data with available slack intervals\n",
    "        model_values = [\n",
    "            model_data[model_data['SlackInterval'] == interval][metric].iloc[0]\n",
    "            if not model_data[model_data['SlackInterval'] == interval].empty \n",
    "            else 0 \n",
    "            for interval in slack_intervals\n",
    "        ]\n",
    "        \n",
    "        ax.bar(x + j*bar_width, \n",
    "               model_values,\n",
    "               bar_width,\n",
    "               label=label,\n",
    "               color=color,\n",
    "               alpha=0.9)\n",
    "    \n",
    "    ax.set_xlabel(\"Scenario slack\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(ylabel)\n",
    "    ax.set_xticks(x + bar_width)\n",
    "    ax.set_xticklabels(slack_intervals, rotation=45)\n",
    "    ax.grid(True, axis='y')\n",
    "\n",
    "# Add a global legend (once for all subplots)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center', bbox_to_anchor=(0.5, -0.1), ncol=3, title=\"Model\", frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.suptitle(\"Impact of scenario slack\", y=1.02)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Good: </b>Impact of number of disrupted flights\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Define a color map and human-readable labels for the models\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() and 'myopic' not in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() and 'myopic' not in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in sorted(merged_df['Model'].unique(), \n",
    "                           key=lambda x: (0 if 'proactive' in x.lower() and 'myopic' not in x.lower() else\n",
    "                                        1 if 'myopic' in x.lower() else \n",
    "                                        2))\n",
    "}\n",
    "\n",
    "# Define the metrics and corresponding y-axis labels\n",
    "metrics = [\n",
    "    (\"TotalDelays\", \"Delays (minutes)\"),\n",
    "    (\"TailSwaps\", \"Tail swaps\"), \n",
    "    (\"TotalCancelledFlights\", \"Cancelled flights\")\n",
    "]\n",
    "\n",
    "# Aggregate data by taking the mean of the numeric metrics for each (Model, ActualDisruptedFlights)\n",
    "agg_df = (\n",
    "    merged_df\n",
    "    .groupby(['Model', 'ActualDisruptedFlights'], as_index=False)[[m[0] for m in metrics]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharex=True)\n",
    "\n",
    "for i, (metric, ylabel) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot bars for each model in the specified order\n",
    "    bar_offset = -0.25  # Start with leftmost position\n",
    "    for model_name, (color, label) in model_colors.items():\n",
    "        model_data = agg_df[agg_df['Model'] == model_name].copy()\n",
    "        # Sort by ActualDisruptedFlights\n",
    "        model_data = model_data.sort_values(by='ActualDisruptedFlights')\n",
    "        \n",
    "        x = model_data['ActualDisruptedFlights']\n",
    "        y = model_data[metric]\n",
    "            \n",
    "        ax.bar(\n",
    "            x + bar_offset,  # Offset bars\n",
    "            y,\n",
    "            width=0.25,\n",
    "            label=label,\n",
    "            color=color,\n",
    "            alpha=0.9\n",
    "        )\n",
    "        bar_offset += 0.25  # Move to next position\n",
    "\n",
    "    ax.set_xlabel(\"Number of disrupted flights\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(ylabel)\n",
    "    ax.grid(True, axis='y')\n",
    "\n",
    "# Add a global legend (once for all subplots)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center', bbox_to_anchor=(0.5, -0.03), ncol=3, title=\"Model\", frameon=False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.suptitle(\"Impact of number of disrupted flights\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Irrelevant: </b>Reward vs. AvgUncertaintyProbability (stochastic scenarios)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Filter the DataFrame for stochastic_low, stochastic_medium, and stochastic_high scenarios\n",
    "filtered_stochastic_df = merged_df[\n",
    "    merged_df['Scenario'].str.startswith('stochastic_low') |\n",
    "    merged_df['Scenario'].str.startswith('stochastic_medium') |\n",
    "    merged_df['Scenario'].str.startswith('stochastic_high') |\n",
    "    merged_df['Scenario'].str.startswith('mixed_low') |\n",
    "    merged_df['Scenario'].str.startswith('mixed_medium') |\n",
    "    merged_df['Scenario'].str.startswith('mixed_high')\n",
    "]\n",
    "\n",
    "# Define a color map for the models\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in filtered_stochastic_df['Model'].unique()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each model separately with regression lines\n",
    "for model_name, (color, label) in model_colors.items():\n",
    "    model_data = filtered_stochastic_df[filtered_stochastic_df['Model'] == model_name]\n",
    "    x = model_data['AvgUncertaintyProbability'].values.reshape(-1, 1)\n",
    "    y = model_data['TotalReward'].values\n",
    "    \n",
    "    # Plot scatter points\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        c=color,\n",
    "        label=label,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    # Linear regression (degree 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    x_pred = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    y_pred = lr.predict(x_pred)\n",
    "    plt.plot(x_pred, y_pred, '--', color=color, alpha=1)\n",
    "    \n",
    "    # Polynomial regression (degree 2)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(x_poly, y)\n",
    "    x_pred_poly = poly.transform(x_pred)\n",
    "    y_pred_poly = lr2.predict(x_pred_poly)\n",
    "    plt.plot(x_pred, y_pred_poly, '-', color=color, alpha=1)\n",
    "\n",
    "plt.title(\"Reward vs. AvgUncertaintyProbability (stochastic scenarios)\")\n",
    "plt.xlabel(\"AvgUncertaintyProbability\")\n",
    "plt.ylabel(\"TotalReward\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Irrelevant: </b>Reward vs. AvgAircraftProbability (all scenarios)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define a color map for the models with custom labels\n",
    "model_colors = {\n",
    "    model_name: (\n",
    "        'orange' if 'proactive' in model_name.lower() else\n",
    "        'blue' if 'myopic' in model_name.lower() else \n",
    "        'green',\n",
    "        'Proactive-U' if 'proactive' in model_name.lower() else\n",
    "        'Proactive-N' if 'myopic' in model_name.lower() else\n",
    "        'Reactive'\n",
    "    )\n",
    "    for model_name in filtered_stochastic_df['Model'].unique()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each model separately with regression lines\n",
    "for model_name, (color, label) in model_colors.items():\n",
    "    model_data = merged_df[merged_df['Model'] == model_name]\n",
    "    x = model_data['AvgAircraftProbability'].values.reshape(-1, 1)\n",
    "    y = model_data['TotalReward'].values\n",
    "    \n",
    "    # Plot scatter points\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        c=color,\n",
    "        label=label,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    # Linear regression (degree 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    x_pred = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    y_pred = lr.predict(x_pred)\n",
    "    plt.plot(x_pred, y_pred, '--', color=color, alpha=1)\n",
    "    \n",
    "    # Polynomial regression (degree 2)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(x_poly, y)\n",
    "    x_pred_poly = poly.transform(x_pred)\n",
    "    y_pred_poly = lr2.predict(x_pred_poly)\n",
    "    plt.plot(x_pred, y_pred_poly, '-', color=color, alpha=1)\n",
    "\n",
    "plt.title(\"Reward vs. AvgAircraftProbability (all scenarios)\")\n",
    "plt.xlabel(\"AvgAircraftProbability\")\n",
    "plt.ylabel(\"TotalReward\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Irrelevant: </b>Reward vs. ScenarioSlack (all scenarios)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model_name, (color, label) in model_colors.items():\n",
    "    model_data = merged_df[merged_df['Model'] == model_name]\n",
    "    x = model_data['ScenarioSlack'].values.reshape(-1, 1)\n",
    "    y = model_data['TotalReward'].values\n",
    "    \n",
    "    # Plot scatter points\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        c=color,\n",
    "        label=label,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    # Linear regression (degree 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    x_pred = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    y_pred = lr.predict(x_pred)\n",
    "    plt.plot(x_pred, y_pred, '--', color=color, alpha=1)\n",
    "    \n",
    "    # Polynomial regression (degree 2) for a smoothed curve\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(x_poly, y)\n",
    "    x_pred_poly = poly.transform(x_pred)\n",
    "    y_pred_poly = lr2.predict(x_pred_poly)\n",
    "    plt.plot(x_pred, y_pred_poly, '-', color=color, alpha=1)\n",
    "\n",
    "plt.title(\"Reward vs. ScenarioSlack (all scenarios)\")\n",
    "plt.xlabel(\"ScenarioSlack\")\n",
    "plt.ylabel(\"TotalReward\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Irrelevant: </b>TotalDelay vs. AvgAircraftProbability (all scenarios)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model_name, (color, label) in model_colors.items():\n",
    "    model_data = merged_df[merged_df['Model'] == model_name]\n",
    "    x = model_data['AvgAircraftProbability'].values.reshape(-1, 1)\n",
    "    y = model_data['TotalDelays'].values\n",
    "    \n",
    "    # Plot scatter points\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        c=color,\n",
    "        label=label,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    # Linear regression (degree 1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    x_pred = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    y_pred = lr.predict(x_pred)\n",
    "    plt.plot(x_pred, y_pred, '--', color=color, alpha=1)\n",
    "    \n",
    "    # Polynomial regression (degree 2) for a smoothed curve\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly.fit_transform(x)\n",
    "    lr2 = LinearRegression()\n",
    "    lr2.fit(x_poly, y)\n",
    "    x_pred_poly = poly.transform(x_pred)\n",
    "    y_pred_poly = lr2.predict(x_pred_poly)\n",
    "    plt.plot(x_pred, y_pred_poly, '-', color=color, alpha=1)\n",
    "\n",
    "plt.title(\"Delays vs. AvgAircraftProbability (all scenarios)\")\n",
    "plt.xlabel(\"AvgAircraftProbability\")\n",
    "plt.ylabel(\"Delays (minutes)\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Irrelevant: </b>Plot too unclear\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()  # Create second y-axis sharing same x-axis\n",
    "\n",
    "# Define bucket boundaries\n",
    "buckets = np.arange(0, 1.05, 0.05)  # Creates buckets 0-0.05, 0.05-0.1, etc.\n",
    "\n",
    "for model_name, (color, label) in model_colors.items():\n",
    "    model_data = merged_df[merged_df['Model'] == model_name]\n",
    "    \n",
    "    # Initialize lists to store bucket averages\n",
    "    x_means = []\n",
    "    y_means = []\n",
    "    y2_means = []\n",
    "    \n",
    "    # Calculate averages for each bucket\n",
    "    for i in range(len(buckets)-1):\n",
    "        bucket_data = model_data[\n",
    "            (model_data['AvgAircraftProbability'] >= buckets[i]) & \n",
    "            (model_data['AvgAircraftProbability'] < buckets[i+1])\n",
    "        ]\n",
    "        \n",
    "        if not bucket_data.empty:\n",
    "            x_means.append(bucket_data['AvgAircraftProbability'].mean())\n",
    "            y_means.append(bucket_data['TotalDelays'].mean())\n",
    "            y2_means.append(bucket_data['TotalCancelledFlights'].mean())\n",
    "    \n",
    "    # Plot the bucket averages for TotalDelays on first y-axis with higher zorder\n",
    "    ax1.plot(x_means, y_means,\n",
    "             color=color,\n",
    "             label=f\"{label} - delays\",\n",
    "             marker='o',\n",
    "             markersize=4,\n",
    "             alpha=0.7,\n",
    "             zorder=5)\n",
    "             \n",
    "    # Plot the bucket averages for TotalCancelledFlights on second y-axis with higher zorder\n",
    "    ax2.plot(x_means, y2_means,\n",
    "             color=color,\n",
    "             label=f\"{label} - cancellations\",\n",
    "             linestyle='--',\n",
    "             marker='o',\n",
    "             markersize=4,\n",
    "             alpha=0.7,\n",
    "             zorder=5)\n",
    "\n",
    "ax1.set_xlabel(\"Avg expected aircraft disruption\")\n",
    "ax1.set_ylabel(\"Delays (minutes)\")\n",
    "ax2.set_ylabel(\"Total cancelled flights\")\n",
    "\n",
    "# Add legends for both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, bbox_to_anchor=(0.5, -0.25), loc='center', ncol=3, frameon=False)\n",
    "\n",
    "plt.title(\"Impact of disruption scale on delays and cancellations\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
