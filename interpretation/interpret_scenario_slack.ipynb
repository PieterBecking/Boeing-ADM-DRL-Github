{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disruption type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario ID: 2\n",
      "Data Folder: ../data/Testing/6ac-700-diverse/\n",
      "                          Scenario  ScenarioSlack  FullyDisruptedCount  \\\n",
      "0    deterministic_na_Scenario_001       0.668537                    2   \n",
      "1    deterministic_na_Scenario_002       0.663849                    2   \n",
      "2    deterministic_na_Scenario_003       0.709877                    2   \n",
      "3    deterministic_na_Scenario_004       0.593474                    2   \n",
      "4    deterministic_na_Scenario_005       0.702314                    2   \n",
      "..                             ...            ...                  ...   \n",
      "695        mixed_high_Scenario_096       0.684293                    1   \n",
      "696        mixed_high_Scenario_097       0.680254                    1   \n",
      "697        mixed_high_Scenario_098       0.664708                    1   \n",
      "698        mixed_high_Scenario_099       0.658414                    1   \n",
      "699        mixed_high_Scenario_100       0.657952                    1   \n",
      "\n",
      "     UncertainCount  AvgAircraftProbability  AvgUncertaintyProbability  \n",
      "0                 0                0.333333                   0.000000  \n",
      "1                 0                0.333333                   0.000000  \n",
      "2                 0                0.333333                   0.000000  \n",
      "3                 0                0.333333                   0.000000  \n",
      "4                 0                0.333333                   0.000000  \n",
      "..              ...                     ...                        ...  \n",
      "695               1                0.255128                   0.530767  \n",
      "696               1                0.315262                   0.891574  \n",
      "697               1                0.301095                   0.806572  \n",
      "698               1                0.303156                   0.818936  \n",
      "699               1                0.253686                   0.522116  \n",
      "\n",
      "[700 rows x 6 columns]\n",
      "Slack metrics saved to ../logs/scenarios/scenario_slack_metrics_2.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "def time_to_minutes(t):\n",
    "    h, m = map(int, t.split(':'))\n",
    "    return h * 60 + m\n",
    "\n",
    "def calculate_slack_for_scenario(scenario_data):\n",
    "    \"\"\"\n",
    "    Calculate the slack metric for the given scenario.\n",
    "\n",
    "    Slack is defined as:\n",
    "        Slack_ac = (Total flight time of aircraft ac) / H\n",
    "    where H is the total scenario horizon (difference in minutes between the earliest departure and the latest arrival).\n",
    "\n",
    "    The scenario slack is the average slack across all aircraft.\n",
    "    \"\"\"\n",
    "    flights = scenario_data.get('flights', {})\n",
    "    aircraft_ids = scenario_data.get('aircraft_ids', [])\n",
    "\n",
    "    if len(flights) == 0:\n",
    "        # No flights: scenario slack = 0\n",
    "        return 0.0\n",
    "\n",
    "    # Identify the overall scenario horizon\n",
    "    dep_times = [time_to_minutes(f_data['DepTime']) for f_data in flights.values()]\n",
    "    arr_times = [time_to_minutes(f_data['ArrTime']) for f_data in flights.values()]\n",
    "    earliest_dep = min(dep_times)\n",
    "    latest_arr = max(arr_times)\n",
    "    horizon = max(latest_arr - earliest_dep, 1)  # Ensure no division by zero\n",
    "\n",
    "    # Organize flights by aircraft\n",
    "    aircraft_flights = {ac: [] for ac in aircraft_ids}\n",
    "    for f_data in flights.values():\n",
    "        dep = time_to_minutes(f_data['DepTime'])\n",
    "        arr = time_to_minutes(f_data['ArrTime'])\n",
    "        ac = f_data['Aircraft']\n",
    "        aircraft_flights[ac].append((dep, arr))\n",
    "\n",
    "    # Calculate slack per aircraft\n",
    "    aircraft_slacks = []\n",
    "    for ac, f_list in aircraft_flights.items():\n",
    "        if len(f_list) == 0:\n",
    "            # No flights for this aircraft: slack = 0\n",
    "            ac_slack = 0.0\n",
    "        else:\n",
    "            total_flight_time = sum(arr - dep for dep, arr in f_list)\n",
    "            ac_slack = total_flight_time / horizon\n",
    "        aircraft_slacks.append(ac_slack)\n",
    "\n",
    "    # Scenario slack is the average slack of all aircraft\n",
    "    scenario_slack = sum(aircraft_slacks) / len(aircraft_slacks) if aircraft_slacks else 0.0\n",
    "    return scenario_slack\n",
    "\n",
    "def extract_disruption_stats(scenario_data):\n",
    "    \"\"\"\n",
    "    Extract disruption statistics:\n",
    "    - Count of fully disrupted (prob = 1.0)\n",
    "    - Count of uncertain disruptions (0 < prob < 1.0)\n",
    "    - Average probability across all aircraft (where an aircraft's probability is the max disruption probability it faces, \n",
    "      with 1.0 for fully disrupted and 0.0 if no disruption)\n",
    "    - Average uncertainty probability (average of all disruptions where 0<prob<1.0, excluding 0 and 1)\n",
    "    \"\"\"\n",
    "    disruptions_info = scenario_data.get('disruptions', {})\n",
    "    disruptions_list = disruptions_info.get('disruptions', [])\n",
    "    total_aircraft = disruptions_info.get('total_aircraft', 0)\n",
    "\n",
    "    if total_aircraft == 0:\n",
    "        # No aircraft or no disruptions\n",
    "        return 0, 0, 0.0, 0.0\n",
    "\n",
    "    fully_disrupted_count = sum(1 for d in disruptions_list if d.get('probability', 0.0) == 1.0)\n",
    "    uncertain_disruptions = [d for d in disruptions_list if 0.0 < d.get('probability', 0.0) < 1.0]\n",
    "    uncertain_count = len(uncertain_disruptions)\n",
    "\n",
    "    # Calculate average probability of all aircraft:\n",
    "    # For each aircraft, find the max probability of any disruption it faces.\n",
    "    # If no disruption, probability = 0.0\n",
    "    aircraft_ids = scenario_data.get('aircraft_ids', [])\n",
    "    ac_prob_map = {ac: 0.0 for ac in aircraft_ids}  # default 0.0 if no disruptions\n",
    "\n",
    "    for d in disruptions_list:\n",
    "        ac_id = d.get('aircraft_id')\n",
    "        p = d.get('probability', 0.0)\n",
    "        # Keep the max probability for that aircraft\n",
    "        if ac_id in ac_prob_map:\n",
    "            ac_prob_map[ac_id] = max(ac_prob_map[ac_id], p)\n",
    "\n",
    "    avg_ac_prob = sum(ac_prob_map.values()) / total_aircraft if total_aircraft > 0 else 0.0\n",
    "\n",
    "    # Average uncertainty probability (only consider disruptions where 0<prob<1)\n",
    "    if len(uncertain_disruptions) > 0:\n",
    "        avg_uncertainty_prob = np.mean([d['probability'] for d in uncertain_disruptions])\n",
    "    else:\n",
    "        avg_uncertainty_prob = 0.0\n",
    "\n",
    "    return fully_disrupted_count, uncertain_count, avg_ac_prob, avg_uncertainty_prob\n",
    "\n",
    "# Path to the scenarios folder\n",
    "scenario_folder_path = \"../logs/scenarios/\"\n",
    "latest_folder = max(\n",
    "    [f for f in os.listdir(scenario_folder_path) if f.startswith(\"scenario_folder_\")],\n",
    "    key=lambda x: int(x.split('_')[-1].replace('.json', ''))\n",
    ")\n",
    "\n",
    "latest_folder = \"scenario_folder_scenario_2.json\"\n",
    "\n",
    "file_path = os.path.join(scenario_folder_path, latest_folder)\n",
    "\n",
    "# Extract scenario ID\n",
    "scenario_id = file_path.split('_')[-1].split('.')[0]\n",
    "print(f\"Scenario ID: {scenario_id}\")\n",
    "\n",
    "# Load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract the scenarios from the JSON data\n",
    "scenarios = data['outputs']\n",
    "\n",
    "# Extract the data_folder (not strictly necessary for slack calculation, but we print it for context)\n",
    "data_folder = data['data_folder']\n",
    "print(f\"Data Folder: {data_folder}\")\n",
    "\n",
    "# Calculate slack and disruption stats for each scenario and store in a list of dicts\n",
    "results = []\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    scenario_slack = calculate_slack_for_scenario(scenario_data)\n",
    "    fully_disrupted_count, uncertain_count, avg_ac_prob, avg_uncertain_prob = extract_disruption_stats(scenario_data)\n",
    "    results.append({\n",
    "        \"Scenario\": scenario_name,\n",
    "        \"ScenarioSlack\": scenario_slack,\n",
    "        \"FullyDisruptedCount\": fully_disrupted_count,\n",
    "        \"UncertainCount\": uncertain_count,\n",
    "        \"AvgAircraftProbability\": avg_ac_prob,\n",
    "        \"AvgUncertaintyProbability\": avg_uncertain_prob\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "scenarios_df = pd.DataFrame(results)\n",
    "print(scenarios_df)\n",
    "\n",
    "# Save the slack results to CSV\n",
    "output_file = os.path.join(scenario_folder_path, f\"scenario_slack_metrics_{scenario_id}.csv\")\n",
    "scenarios_df.to_csv(output_file, index=False)\n",
    "print(f\"Slack metrics saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on data folder: ../data/Testing/6ac-700-diverse/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from src.environment import AircraftDisruptionEnv\n",
    "from scripts.utils import load_scenario_data, NumpyEncoder, get_training_metadata\n",
    "from scripts.logger import create_new_id, log_inference_metadata, find_corresponding_training_id, convert_to_serializable\n",
    "\n",
    "def run_inference_dqn_single(model_path, scenario_folder, env_type, seed):\n",
    "    \"\"\"\n",
    "    Runs inference on a single scenario and returns the total reward.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    data_dict = load_scenario_data(scenario_folder)\n",
    "    aircraft_dict = data_dict['aircraft']\n",
    "    flights_dict = data_dict['flights']\n",
    "    rotations_dict = data_dict['rotations']\n",
    "    alt_aircraft_dict = data_dict['alt_aircraft']\n",
    "    config_dict = data_dict['config']\n",
    "\n",
    "    env = AircraftDisruptionEnv(\n",
    "        aircraft_dict, flights_dict, rotations_dict, alt_aircraft_dict, config_dict, env_type=env_type\n",
    "    )\n",
    "\n",
    "    model = DQN.load(model_path)\n",
    "    model.set_env(env)\n",
    "    model.policy.set_training_mode(False)\n",
    "    model.exploration_rate = 0.0\n",
    "\n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    done_flag = False\n",
    "    total_reward = 0\n",
    "    step_num = 0\n",
    "    max_steps = 1000\n",
    "\n",
    "    while not done_flag and step_num < max_steps:\n",
    "        action_mask = obs['action_mask']\n",
    "        obs = {key: np.array(value, dtype=np.float32) for key, value in obs.items()}\n",
    "        obs_tensor = model.policy.obs_to_tensor(obs)[0]\n",
    "        q_values = model.policy.q_net(obs_tensor).detach().cpu().numpy().squeeze()\n",
    "\n",
    "        masked_q_values = q_values.copy()\n",
    "        masked_q_values[action_mask == 0] = -np.inf\n",
    "\n",
    "        # If no valid actions remain, break out\n",
    "        if np.all(np.isinf(masked_q_values)):\n",
    "            break\n",
    "\n",
    "        action = np.argmax(masked_q_values)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        done_flag = terminated or truncated\n",
    "        step_num += 1\n",
    "\n",
    "    total_delays = env.scenario_wide_delay_minutes\n",
    "    total_cancelled_flights = env.scenario_wide_cancelled_flights\n",
    "    end_time = time.time()\n",
    "    scenario_time = end_time - start_time\n",
    "    scenario_steps = env.scenario_wide_steps\n",
    "    scenario_resolved_conflicts = env.scenario_wide_resolved_conflicts\n",
    "    solution_slack = env.scenario_wide_solution_slack\n",
    "\n",
    "    return total_reward, total_delays, total_cancelled_flights, scenario_time, scenario_steps, scenario_resolved_conflicts, solution_slack\n",
    "\n",
    "def run_inference_on_data_folder(model_paths, data_folder, seeds):\n",
    "    \"\"\"\n",
    "    Runs inference on all scenarios found in 'data_folder', for each model in 'model_paths' and each seed in 'seeds'.\n",
    "\n",
    "    Args:\n",
    "        model_paths (list): List of model paths to run inference with.\n",
    "        data_folder (str): Path to the folder containing scenario subfolders.\n",
    "        env_type (str): Type of environment (\"myopic\", \"proactive\", \"reactive\").\n",
    "        seeds (list): List of seeds for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing scenario, model, seed, and total reward.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify all scenario folders within data_folder\n",
    "    scenario_folders = [\n",
    "        os.path.join(data_folder, folder)\n",
    "        for folder in os.listdir(data_folder)\n",
    "        if os.path.isdir(os.path.join(data_folder, folder))\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for scenario_folder in scenario_folders:\n",
    "        scenario_name = os.path.basename(scenario_folder)\n",
    "        for model_path in model_paths:\n",
    "            for seed in seeds:\n",
    "                # extract env_type from model_path\n",
    "                env_type = model_path.split(\"/\")[-2]\n",
    "                total_reward, total_delays, total_cancelled_flights, scenario_time, scenario_steps, scenario_resolved_conflicts, solution_slack = run_inference_dqn_single(model_path, scenario_folder, env_type, seed)\n",
    "                results.append({\n",
    "                    \"Scenario\": scenario_name,\n",
    "                    \"Model\": os.path.basename(model_path),\n",
    "                    \"Seed\": seed,\n",
    "                    \"TotalReward\": total_reward,\n",
    "                    \"TotalDelays\": total_delays,\n",
    "                    \"TotalCancelledFlights\": total_cancelled_flights,\n",
    "                    \"ScenarioTime\": scenario_time,\n",
    "                    \"ScenarioSteps\": scenario_steps,\n",
    "                    \"ScenarioResolvedConflicts\": scenario_resolved_conflicts,\n",
    "                    \"SolutionSlack\": solution_slack\n",
    "                })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data_folder = data['data_folder']\n",
    "print(f\"inferencing on data folder: {data_folder}\")\n",
    "\n",
    "# Define models and seeds\n",
    "model_paths = [\n",
    "    \"../trained_models/dqn/6ac-700-diverse/23/myopic-training_8.zip\",\n",
    "    \"../trained_models/dqn/6ac-700-diverse/23/proactive-training_9.zip\",\n",
    "    \"../trained_models/dqn/6ac-700-diverse/23/reactive-training_10.zip\"\n",
    "]\n",
    "seeds = [25, 26]\n",
    "\n",
    "results_df = run_inference_on_data_folder(model_paths, data_folder, seeds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Results (After Merging):\n",
      "                          Scenario                     Model  Seed  \\\n",
      "4180  stochastic_high_Scenario_037  reactive-training_10.zip    25   \n",
      "4181  stochastic_high_Scenario_037  reactive-training_10.zip    26   \n",
      "4182        mixed_low_Scenario_033     myopic-training_8.zip    25   \n",
      "4183        mixed_low_Scenario_033     myopic-training_8.zip    26   \n",
      "4184        mixed_low_Scenario_033  proactive-training_9.zip    25   \n",
      "4185        mixed_low_Scenario_033  proactive-training_9.zip    26   \n",
      "4186        mixed_low_Scenario_033  reactive-training_10.zip    25   \n",
      "4187        mixed_low_Scenario_033  reactive-training_10.zip    26   \n",
      "4188   stochastic_low_Scenario_045     myopic-training_8.zip    25   \n",
      "4189   stochastic_low_Scenario_045     myopic-training_8.zip    26   \n",
      "4190   stochastic_low_Scenario_045  proactive-training_9.zip    25   \n",
      "4191   stochastic_low_Scenario_045  proactive-training_9.zip    26   \n",
      "4192   stochastic_low_Scenario_045  reactive-training_10.zip    25   \n",
      "4193   stochastic_low_Scenario_045  reactive-training_10.zip    26   \n",
      "4194  stochastic_high_Scenario_008     myopic-training_8.zip    25   \n",
      "4195  stochastic_high_Scenario_008     myopic-training_8.zip    26   \n",
      "4196  stochastic_high_Scenario_008  proactive-training_9.zip    25   \n",
      "4197  stochastic_high_Scenario_008  proactive-training_9.zip    26   \n",
      "4198  stochastic_high_Scenario_008  reactive-training_10.zip    25   \n",
      "4199  stochastic_high_Scenario_008  reactive-training_10.zip    26   \n",
      "\n",
      "      TotalReward  TotalDelays  TotalCancelledFlights  ScenarioTime  \\\n",
      "4180       -360.0          0.0                      0      0.027741   \n",
      "4181     -27160.0          0.0                      5      0.030487   \n",
      "4182     -20460.0          0.0                      3      0.032857   \n",
      "4183     -10460.0          0.0                      1      0.033160   \n",
      "4184     -20460.0          0.0                      3      0.032980   \n",
      "4185     -20460.0          0.0                      3      0.033844   \n",
      "4186      -2959.3        714.0                      0      0.035479   \n",
      "4187       7040.7        714.0                      0      0.033988   \n",
      "4188      -2155.5          0.0                      0      0.031272   \n",
      "4189     -22695.5          0.0                      4      0.031174   \n",
      "4190     -12700.0          0.0                      2      0.030596   \n",
      "4191      -2160.0          0.0                      0      0.029740   \n",
      "4192     -15200.0        458.0                      2      0.031883   \n",
      "4193      -4660.0        458.0                      0      0.031252   \n",
      "4194      -2160.0          0.0                      0      0.030819   \n",
      "4195     -12160.0          0.0                      2      0.030223   \n",
      "4196     -12380.4         28.0                      2      0.031817   \n",
      "4197     -12380.4         28.0                      2      0.032370   \n",
      "4198     -12160.0          0.0                      2      0.031157   \n",
      "4199     -12160.0          0.0                      2      0.030161   \n",
      "\n",
      "      ScenarioSteps  ScenarioResolvedConflicts  SolutionSlack  ScenarioSlack  \\\n",
      "4180              3                          0       0.000000       0.660784   \n",
      "4181              8                          0       0.464072       0.660784   \n",
      "4182             13                          0       0.541279       0.672804   \n",
      "4183             13                          0       0.000000       0.672804   \n",
      "4184             13                          0       0.541279       0.672804   \n",
      "4185             13                          0       0.541279       0.672804   \n",
      "4186             13                          1       0.487629       0.672804   \n",
      "4187             13                          3       0.487629       0.672804   \n",
      "4188              8                          0       0.000000       0.669473   \n",
      "4189              9                          0       0.507556       0.669473   \n",
      "4190              9                          0       0.000000       0.669473   \n",
      "4191              8                          0       0.000000       0.669473   \n",
      "4192              9                          0       0.469416       0.669473   \n",
      "4193              8                          0       0.000000       0.669473   \n",
      "4194              8                          0       0.000000       0.651480   \n",
      "4195              8                          0       0.569204       0.651480   \n",
      "4196              8                          0       0.551397       0.651480   \n",
      "4197              8                          0       0.551397       0.651480   \n",
      "4198              8                          0       0.569204       0.651480   \n",
      "4199              8                          0       0.569204       0.651480   \n",
      "\n",
      "      FullyDisruptedCount  UncertainCount  AvgAircraftProbability  \\\n",
      "4180                    0               2                0.223291   \n",
      "4181                    0               2                0.223291   \n",
      "4182                    1               1                0.241773   \n",
      "4183                    1               1                0.241773   \n",
      "4184                    1               1                0.241773   \n",
      "4185                    1               1                0.241773   \n",
      "4186                    1               1                0.241773   \n",
      "4187                    1               1                0.241773   \n",
      "4188                    0               2                0.115895   \n",
      "4189                    0               2                0.115895   \n",
      "4190                    0               2                0.115895   \n",
      "4191                    0               2                0.115895   \n",
      "4192                    0               2                0.115895   \n",
      "4193                    0               2                0.115895   \n",
      "4194                    0               2                0.241254   \n",
      "4195                    0               2                0.241254   \n",
      "4196                    0               2                0.241254   \n",
      "4197                    0               2                0.241254   \n",
      "4198                    0               2                0.241254   \n",
      "4199                    0               2                0.241254   \n",
      "\n",
      "      AvgUncertaintyProbability  \n",
      "4180                   0.669874  \n",
      "4181                   0.669874  \n",
      "4182                   0.450636  \n",
      "4183                   0.450636  \n",
      "4184                   0.450636  \n",
      "4185                   0.450636  \n",
      "4186                   0.450636  \n",
      "4187                   0.450636  \n",
      "4188                   0.347684  \n",
      "4189                   0.347684  \n",
      "4190                   0.347684  \n",
      "4191                   0.347684  \n",
      "4192                   0.347684  \n",
      "4193                   0.347684  \n",
      "4194                   0.723762  \n",
      "4195                   0.723762  \n",
      "4196                   0.723762  \n",
      "4197                   0.723762  \n",
      "4198                   0.723762  \n",
      "4199                   0.723762  \n",
      "Inference results with scenario info saved to ../logs/scenarios/scenario_inference_metrics_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Merge scenario-level info from scenarios_df into results_df\n",
    "merged_df = results_df.merge(scenarios_df, on='Scenario', how='left')\n",
    "\n",
    "print(\"Inference Results (After Merging):\")\n",
    "print(merged_df.tail(20))\n",
    "\n",
    "# Save the merged results to CSV\n",
    "merged_output_file = os.path.join(scenario_folder_path, f\"scenario_inference_metrics_{scenario_id}.csv\")\n",
    "merged_df.to_csv(merged_output_file, index=False)\n",
    "print(f\"Inference results with scenario info saved to {merged_output_file}\")\n",
    "\n",
    "# print all column names\n",
    "# print(results_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Models Across All Scenarios:\n",
      "                          Mean_Reward  Mean_Runtime  Mean_Steps  Mean_Delays  \\\n",
      "Model                                                                          \n",
      "myopic-training_8.zip       -10750.07          0.03        7.98       204.82   \n",
      "proactive-training_9.zip    -12996.75          0.03        8.26        40.02   \n",
      "reactive-training_10.zip    -10443.47          0.03        7.76       245.48   \n",
      "\n",
      "                          Mean_CancelledFlights  Mean_ResolvedConflicts  \n",
      "Model                                                                    \n",
      "myopic-training_8.zip                      1.88                    0.38  \n",
      "proactive-training_9.zip                   2.14                    0.09  \n",
      "reactive-training_10.zip                   1.79                    0.41  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison_table = (\n",
    "    merged_df\n",
    "    .groupby('Model')\n",
    "    .agg(\n",
    "        Mean_Reward=('TotalReward', 'mean'),\n",
    "        Mean_Runtime=('ScenarioTime', 'mean'),\n",
    "        Mean_Steps=('ScenarioSteps', 'mean'),\n",
    "        Mean_Delays=('TotalDelays', 'mean'),\n",
    "        Mean_CancelledFlights=('TotalCancelledFlights', 'mean'),\n",
    "        Mean_ResolvedConflicts=('ScenarioResolvedConflicts', 'mean'),\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"Comparison of Models Across All Scenarios:\")\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Models Across stochastic_low and stochastic_high Scenarios:\n",
      "                          Mean_Reward_stochastic_high  \\\n",
      "Model                                                   \n",
      "myopic-training_8.zip                       -11147.38   \n",
      "proactive-training_9.zip                    -13487.27   \n",
      "reactive-training_10.zip                    -10708.46   \n",
      "\n",
      "                          Mean_Reward_stochastic_low  \\\n",
      "Model                                                  \n",
      "myopic-training_8.zip                       -6897.85   \n",
      "proactive-training_9.zip                    -7817.78   \n",
      "reactive-training_10.zip                    -6719.67   \n",
      "\n",
      "                          Mean_Runtime_stochastic_high  \\\n",
      "Model                                                    \n",
      "myopic-training_8.zip                             0.03   \n",
      "proactive-training_9.zip                          0.03   \n",
      "reactive-training_10.zip                          0.03   \n",
      "\n",
      "                          Mean_Runtime_stochastic_low  \\\n",
      "Model                                                   \n",
      "myopic-training_8.zip                            0.03   \n",
      "proactive-training_9.zip                         0.03   \n",
      "reactive-training_10.zip                         0.03   \n",
      "\n",
      "                          Mean_Steps_stochastic_high  \\\n",
      "Model                                                  \n",
      "myopic-training_8.zip                           7.86   \n",
      "proactive-training_9.zip                        8.20   \n",
      "reactive-training_10.zip                        7.92   \n",
      "\n",
      "                          Mean_Steps_stochastic_low  \\\n",
      "Model                                                 \n",
      "myopic-training_8.zip                          7.46   \n",
      "proactive-training_9.zip                       7.60   \n",
      "reactive-training_10.zip                       7.24   \n",
      "\n",
      "                          Mean_Delays_stochastic_high  \\\n",
      "Model                                                   \n",
      "myopic-training_8.zip                          215.05   \n",
      "proactive-training_9.zip                        26.26   \n",
      "reactive-training_10.zip                       232.46   \n",
      "\n",
      "                          Mean_Delays_stochastic_low  \\\n",
      "Model                                                  \n",
      "myopic-training_8.zip                         190.88   \n",
      "proactive-training_9.zip                       43.50   \n",
      "reactive-training_10.zip                      217.90   \n",
      "\n",
      "                          Mean_CancelledFlights_stochastic_high  \\\n",
      "Model                                                             \n",
      "myopic-training_8.zip                                      1.88   \n",
      "proactive-training_9.zip                                   2.24   \n",
      "reactive-training_10.zip                                   1.95   \n",
      "\n",
      "                          Mean_CancelledFlights_stochastic_low  \\\n",
      "Model                                                            \n",
      "myopic-training_8.zip                                     0.96   \n",
      "proactive-training_9.zip                                  1.12   \n",
      "reactive-training_10.zip                                  0.88   \n",
      "\n",
      "                          Mean_ResolvedConflicts_stochastic_high  \\\n",
      "Model                                                              \n",
      "myopic-training_8.zip                                       0.32   \n",
      "proactive-training_9.zip                                    0.06   \n",
      "reactive-training_10.zip                                    0.52   \n",
      "\n",
      "                          Mean_ResolvedConflicts_stochastic_low  \n",
      "Model                                                            \n",
      "myopic-training_8.zip                                      0.13  \n",
      "proactive-training_9.zip                                   0.04  \n",
      "reactive-training_10.zip                                   0.17  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/gwyqzldd12bg_s3mrl40tp6r0000gn/T/ipykernel_65521/1350057505.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['ScenarioType'] = np.where(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Filter scenarios that start with 'stochastic_low' or 'stochastic_high'\n",
    "filtered_df = merged_df[\n",
    "    merged_df['Scenario'].str.startswith('stochastic_low') | \n",
    "    merged_df['Scenario'].str.startswith('stochastic_high')\n",
    "]\n",
    "\n",
    "# Create a scenario type column for easier grouping\n",
    "filtered_df['ScenarioType'] = np.where(\n",
    "    filtered_df['Scenario'].str.startswith('stochastic_low'), \n",
    "    'stochastic_low', \n",
    "    'stochastic_high'\n",
    ")\n",
    "\n",
    "# Group by Model and ScenarioType and compute the desired metrics\n",
    "inference_table = (\n",
    "    filtered_df\n",
    "    .groupby(['Model', 'ScenarioType'])\n",
    "    .agg(\n",
    "        Mean_Reward=('TotalReward', 'mean'),\n",
    "        Mean_Runtime=('ScenarioTime', 'mean'),\n",
    "        Mean_Steps=('ScenarioSteps', 'mean'),\n",
    "        Mean_Delays=('TotalDelays', 'mean'),\n",
    "        Mean_CancelledFlights=('TotalCancelledFlights', 'mean'),\n",
    "        Mean_ResolvedConflicts=('ScenarioResolvedConflicts', 'mean')\n",
    "    )\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the table to compare models across scenario types in columns\n",
    "inference_table_pivot = inference_table.pivot(index='Model', columns='ScenarioType')\n",
    "# Flatten column names\n",
    "inference_table_pivot.columns = ['_'.join(col).strip() for col in inference_table_pivot.columns.values]\n",
    "\n",
    "print(\"Comparison of Models Across stochastic_low and stochastic_high Scenarios:\")\n",
    "print(inference_table_pivot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
